{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73ce7013",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f3c98cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ff7e4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c43e8003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: /workspace/data/\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = MNIST('/workspace/data/', download=True, transform=transforms.ToTensor())\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c245df5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9344814a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = 50_000\n",
    "n_valid = dataset.data.shape[0] - n_train\n",
    "x_train, y_train = dataset.data[:n_train, :, :].view(n_train, -1) / 255, dataset.targets[:n_train]\n",
    "x_valid, y_valid = dataset.data[n_train:, :, :].view(n_valid, -1) / 255, dataset.targets[n_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfd9c289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1310), tensor(0.3085))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mean, train_std = x_train.mean(), x_train.std()\n",
    "train_mean, train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fd174b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x: torch.Tensor, mean: torch.Tensor, std: torch.Tensor):\n",
    "    return (x - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb3dd285",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = normalize(x_train, train_mean, train_std)\n",
    "# NOTE: use training, not validation mean and std for validation set\n",
    "x_valid = normalize(x_valid, train_mean, train_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "864ff2d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(2.1126e-08), tensor(1.))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.mean(), x_train.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99b9c9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_near_zero(x, tol=1e-3):\n",
    "    return x.abs() < tol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b0761e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(True), tensor(True))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_near_zero(x_train.mean()), test_near_zero(x_train.std() - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b3f36ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 784, tensor(10))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n, m = x_train.shape\n",
    "c = y_train.max() + 1\n",
    "n, m, c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f934171f",
   "metadata": {},
   "source": [
    "## Basic architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fbb30c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num hidden\n",
    "nh = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1592c66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = torch.randn(m, nh)\n",
    "b1 = torch.zeros(nh)  # it gets broadcasted to (n, nh)\n",
    "w2 = torch.randn(nh, 1)\n",
    "b2 = torch.zeros(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03bb8a58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.0059), tensor(0.9924))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this should roughly be (0, 1)\n",
    "x_valid.mean(), x_valid.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35a042eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear(x: torch.Tensor, w: torch.Tensor, b: torch.Tensor):\n",
    "    return (x @ w) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2cc49049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-1.9614), tensor(26.5270))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = linear(x_valid, w1, b1)\n",
    "t.mean(), t.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925f8b42",
   "metadata": {},
   "source": [
    "This is a pretty terrible result. Let's use a simplified Kaiming He init to make mean and std of the output activation closer to (0, 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "05d7ff3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simplified kaiming he init\n",
    "w1 = torch.randn(m, nh) / math.sqrt(m)\n",
    "b1 = torch.zeros(nh)  # it gets broadcasted to (n, nh)\n",
    "w2 = torch.randn(nh, 1) / math.sqrt(nh)\n",
    "b2 = torch.zeros(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7bba0f82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(True), tensor(True))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_near_zero(w1.mean()), test_near_zero(w1.std() - 1 / math.sqrt(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "03b39760",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear(x: torch.Tensor, w: torch.Tensor, b: torch.Tensor):\n",
    "    return (x @ w) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7ecde1b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0690), tensor(0.9727))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ... and so should this, since we used kaiming he init, which is designed to do this\n",
    "t = linear(x_valid, w1, b1)\n",
    "t.mean(), t.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a14fa0b",
   "metadata": {},
   "source": [
    "This is promising, however, it doesn't take into account the non-linearity activation. Modern networks use ReLu, Swish, Mish, etc. The Kaiming He init doesn't work well with such non-linearities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dfda6405",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x: torch.Tensor):\n",
    "    return x.clamp_min(0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "42f92e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = relu(linear(x_valid, w1, b1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "138d10a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.4197), tensor(0.5770))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.mean(), t.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0938513",
   "metadata": {},
   "source": [
    "As you can notice, the output is not centered at 0 and with unit standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "402f5406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kaiming he init for relu\n",
    "# Delving Deep into Rectifiers: Surpassing Human-Level Performance on \n",
    "#   ImageNet Classification (https://arxiv.org/abs/1502.01852)\n",
    "w1 = torch.randn(m, nh) * math.sqrt(2/m)\n",
    "b1 = torch.zeros(nh)  # it gets broadcasted to (n, nh)\n",
    "w2 = torch.randn(nh, 1) * math.sqrt(2/nh)\n",
    "b2 = torch.zeros(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "993fa8e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0002), tensor(0.0503))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1.mean(), w1.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9c3dba9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.5602), tensor(0.8502))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = relu(linear(x_valid, w1, b1))\n",
    "t.mean(), t.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d54430",
   "metadata": {},
   "source": [
    "This gives us a much better standard deviation ― closer to 1. The mean is not close to zero, but that is intentional. The ReLu activation removed every value below 0, thus the mean cannot be zero. Something closer to 0.5 is now expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5425de8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1f9de986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.5532), tensor(0.8531))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = torch.randn(m, nh)\n",
    "w1 = init.kaiming_normal_(w1, mode='fan_out')\n",
    "t = relu(linear(x_valid, w1, b1))\n",
    "t.mean(), t.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ed82b9",
   "metadata": {},
   "source": [
    "What if we change the definition of ReLu to also subtract 0.5, to bring the mean back to 0..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "83908b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what if...\n",
    "def relu_new(x: torch.Tensor):\n",
    "    return x.clamp_min(0.) - 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "75ae80e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0494), tensor(0.8318))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = torch.randn(m, nh)\n",
    "w1 = init.kaiming_normal_(w1, mode='fan_out')\n",
    "t = relu_new(linear(x_valid, w1, b1))\n",
    "t.mean(), t.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd428f49",
   "metadata": {},
   "source": [
    "The mean is now closer to 0 and the standard deviation is more stable and closer to 0.8 ― not perfect, but it's better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdea6862",
   "metadata": {},
   "source": [
    "## Forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3e939cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x):\n",
    "    l1 = linear(x, w1, b1)\n",
    "    l2 = relu(l1)\n",
    "    l3 = linear(l2, w2, b2)\n",
    "    return l3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3313171b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0466],\n",
       "        [0.8612],\n",
       "        [2.0450],\n",
       "        ...,\n",
       "        [0.3272],\n",
       "        [1.6357],\n",
       "        [1.4171]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model(x_valid)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "33ce7af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert y_pred.shape == torch.Size([x_valid.shape[0], 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b20b56",
   "metadata": {},
   "source": [
    "## Loss function: MSE\n",
    "\n",
    "Of course, MSE is not a suitable loss function for multi-class classification; we will use a better loss function soon. For now, let's use MSE to keep things simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "21ac97a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 1])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "41d304a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y_pred: torch.Tensor, y_true: torch.Tensor) -> torch.Tensor:\n",
    "    return (y_pred - y_true).pow(2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d83a7732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(20.7159)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse(y_pred=y_pred, y_true=y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bb827f",
   "metadata": {},
   "source": [
    "## Gradients and backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a8b77d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_grad(inp, targ):\n",
    "    # grad of loss function w.r.t. output of previous layer\n",
    "    inp.g = 2. * (inp.squeeze() - targ).unsqueeze(-1) / inp.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d2c9172b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_grad(inp, out):\n",
    "    # grad of ReLu w.r.t. input activations\n",
    "    inp.g = (inp>0).float() * out.g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "79ac1e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin_grad(inp, out, w, b):\n",
    "    # grad of matmul w.r.t. input\n",
    "    inp.g = out.g @ w.t()\n",
    "    w.g = (inp.unsqueeze(-1) * out.g.unsqueeze(1)).sum(0)\n",
    "    b.g = out.g.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0fef030b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_and_backward(inp, targ):\n",
    "    l1 = inp @ w1 + b1\n",
    "    l2 = relu(l1)\n",
    "    out = l2 @ w2 + b2\n",
    "    # we don't actually need the loss in the backward pass!\n",
    "    loss = mse(out, targ)\n",
    "    \n",
    "    mse_grad(out, targ)\n",
    "    lin_grad(l2, out, w2, b2)\n",
    "    relu_grad(l1, l2)\n",
    "    lin_grad(inp, l1, w1, b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b71daf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_and_backward(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ec66fc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save for testing later\n",
    "w1g = w1.g.clone()\n",
    "w2g = w2.g.clone()\n",
    "b1g = b1.g.clone()\n",
    "b2g = b2.g.clone()\n",
    "ig = x_train.g.clone()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f97d9b",
   "metadata": {},
   "source": [
    "Let's check the results against PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "94320d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "xt2 = x_train.clone().requires_grad_(True)\n",
    "w12 = w1.clone().requires_grad_(True)\n",
    "w22 = w2.clone().requires_grad_(True)\n",
    "b12 = b1.clone().requires_grad_(True)\n",
    "b22 = b2.clone().requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cf571de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(inp, targ):\n",
    "    l1 = inp @ w12 + b12\n",
    "    l2 = relu(l1)\n",
    "    out = l2 @ w22 + b22\n",
    "    # we don't actually need the loss in backward!\n",
    "    return mse(out, targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3d37a7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = forward(xt2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "85cc5ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "617d1be1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_near(a: torch.tensor, b:torch.tensor):\n",
    "    return torch.allclose(a, b, rtol=1e-3, atol=1e-5)\n",
    "\n",
    "test_near(w22.grad, w2g)\n",
    "test_near(b22.grad, b2g)\n",
    "test_near(w12.grad, w1g)\n",
    "test_near(b12.grad, b1g)\n",
    "test_near(xt2.grad, ig )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e1a90b6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0594, -0.3999,  0.1522, -0.3356,  0.2963,  0.8817, -0.1711, -0.0693,\n",
       "          -0.5706, -0.2508,  0.1139, -0.2435,  0.0273,  0.3508, -0.0809,  0.0195,\n",
       "          -0.0805,  0.2433,  0.7586, -0.3073, -0.1211,  0.3047,  0.2199,  0.0074,\n",
       "           0.0019, -0.3475, -0.0736,  0.3731,  0.1078,  0.1344,  0.0013,  0.2045,\n",
       "           0.2504, -0.1791,  0.0068, -0.1838,  0.2169, -0.0431, -0.1259,  0.0087,\n",
       "           0.1221,  0.1463, -0.0648,  0.0897,  0.0583, -0.0732, -0.0294,  0.0917,\n",
       "          -0.2673, -0.1678],\n",
       "         [-0.0594, -0.3999,  0.1522, -0.3356,  0.2963,  0.8817, -0.1711, -0.0693,\n",
       "          -0.5706, -0.2508,  0.1139, -0.2435,  0.0273,  0.3508, -0.0809,  0.0195,\n",
       "          -0.0805,  0.2433,  0.7586, -0.3073, -0.1211,  0.3047,  0.2199,  0.0074,\n",
       "           0.0019, -0.3475, -0.0736,  0.3731,  0.1078,  0.1344,  0.0013,  0.2045,\n",
       "           0.2504, -0.1791,  0.0068, -0.1838,  0.2169, -0.0431, -0.1259,  0.0087,\n",
       "           0.1221,  0.1463, -0.0648,  0.0897,  0.0583, -0.0732, -0.0294,  0.0917,\n",
       "          -0.2673, -0.1678],\n",
       "         [-0.0594, -0.3999,  0.1522, -0.3356,  0.2963,  0.8817, -0.1711, -0.0693,\n",
       "          -0.5706, -0.2508,  0.1139, -0.2435,  0.0273,  0.3508, -0.0809,  0.0195,\n",
       "          -0.0805,  0.2433,  0.7586, -0.3073, -0.1211,  0.3047,  0.2199,  0.0074,\n",
       "           0.0019, -0.3475, -0.0736,  0.3731,  0.1078,  0.1344,  0.0013,  0.2045,\n",
       "           0.2504, -0.1791,  0.0068, -0.1838,  0.2169, -0.0431, -0.1259,  0.0087,\n",
       "           0.1221,  0.1463, -0.0648,  0.0897,  0.0583, -0.0732, -0.0294,  0.0917,\n",
       "          -0.2673, -0.1678]]),\n",
       " tensor([[-0.0659, -0.3545,  0.1296, -0.3400,  0.3333,  0.8710, -0.1418, -0.0652,\n",
       "          -0.6060, -0.2738,  0.1191, -0.2629,  0.0282,  0.3368, -0.0544,  0.0139,\n",
       "          -0.0753,  0.2499,  0.7787, -0.3361, -0.1066,  0.3207,  0.2232,  0.0074,\n",
       "           0.0015, -0.3692, -0.0811,  0.4249,  0.1124,  0.1290,  0.0009,  0.2115,\n",
       "           0.2434, -0.1708,  0.0075, -0.1395,  0.2327, -0.0485, -0.1019,  0.0072,\n",
       "           0.0744,  0.1477, -0.0703,  0.0523,  0.0465, -0.0716, -0.0320,  0.0931,\n",
       "          -0.1985, -0.1859],\n",
       "         [-0.0659, -0.3545,  0.1296, -0.3400,  0.3333,  0.8710, -0.1418, -0.0652,\n",
       "          -0.6060, -0.2738,  0.1191, -0.2629,  0.0282,  0.3368, -0.0544,  0.0139,\n",
       "          -0.0753,  0.2499,  0.7787, -0.3361, -0.1066,  0.3207,  0.2232,  0.0074,\n",
       "           0.0015, -0.3692, -0.0811,  0.4249,  0.1124,  0.1290,  0.0009,  0.2115,\n",
       "           0.2434, -0.1708,  0.0075, -0.1395,  0.2327, -0.0485, -0.1019,  0.0072,\n",
       "           0.0744,  0.1477, -0.0703,  0.0523,  0.0465, -0.0716, -0.0320,  0.0931,\n",
       "          -0.1985, -0.1859],\n",
       "         [-0.0659, -0.3545,  0.1296, -0.3400,  0.3333,  0.8710, -0.1418, -0.0652,\n",
       "          -0.6060, -0.2738,  0.1191, -0.2629,  0.0282,  0.3368, -0.0544,  0.0139,\n",
       "          -0.0753,  0.2499,  0.7787, -0.3361, -0.1066,  0.3207,  0.2232,  0.0074,\n",
       "           0.0015, -0.3692, -0.0811,  0.4249,  0.1124,  0.1290,  0.0009,  0.2115,\n",
       "           0.2434, -0.1708,  0.0075, -0.1395,  0.2327, -0.0485, -0.1019,  0.0072,\n",
       "           0.0744,  0.1477, -0.0703,  0.0523,  0.0465, -0.0716, -0.0320,  0.0931,\n",
       "          -0.1985, -0.1859]]))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w12.grad[:3], w1g[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c5fecd",
   "metadata": {},
   "source": [
    "Gradients are similar, but not as close as we want them to be. Why is that?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
