{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e6abf2e",
   "metadata": {},
   "source": [
    "# Building `makemore` Part 4: Becoming a Backprop Ninja\n",
    "\n",
    "\n",
    "Lecture: [YouTube](https://youtu.be/q8SA3rM6ckI)\n",
    "\n",
    "We are going to manually reimplement what `loss.backward()` does. In this way, we can better understand how gradients flow in the backward pass and get intuition that will prevent us from committing silly mistakes when building a network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cded37e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use(\"seaborn-v0_8-whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00420674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = open(\"./names.txt\", \"r\").read().splitlines()\n",
    "words[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3a23da2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77f2010b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "# build the vacabulary of characters and mapping to/from integers\n",
    "chars = sorted(list(set(\"\".join(words))))\n",
    "s2i = {s: i + 1 for i, s in enumerate(chars)}\n",
    "s2i[\".\"] = 0\n",
    "i2s = {i: s for s, i in s2i.items()}\n",
    "vocab_size = len(i2s)\n",
    "print(i2s)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23a15e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182625, 3]) torch.Size([182625])\n",
      "torch.Size([22655, 3]) torch.Size([22655])\n",
      "torch.Size([22866, 3]) torch.Size([22866])\n"
     ]
    }
   ],
   "source": [
    "block_size = (\n",
    "    3  # context length: how many characters do we take to predict the next one?\n",
    ")\n",
    "\n",
    "\n",
    "def build_dataset(words):\n",
    "    x, y = [], []\n",
    "\n",
    "    for w in words:\n",
    "        context = [0] * block_size\n",
    "        for ch in w + \".\":\n",
    "            ix = s2i[ch]\n",
    "            x.append(context)\n",
    "            y.append(ix)\n",
    "            context = context[1:] + [ix]  # crop and append\n",
    "\n",
    "    x = torch.tensor(x)\n",
    "    y = torch.tensor(y)\n",
    "    print(x.shape, y.shape)\n",
    "    return x, y\n",
    "\n",
    "\n",
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8 * len(words))\n",
    "n2 = int(0.9 * len(words))\n",
    "\n",
    "x_trn, y_trn = build_dataset(words[:n1])  # 80%\n",
    "x_val, y_val = build_dataset(words[n1:n2])  # 10%\n",
    "x_tst, y_tst = build_dataset(words[n2:])  # 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e434476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility function we will use later when comparing manual gradients to PyTorch gradients\n",
    "def cmp(s, dt, t):\n",
    "    ex = torch.all(dt == t.grad).item()\n",
    "    app = torch.allclose(dt, t.grad)\n",
    "    maxdiff = (dt - t.grad).abs().max().item()\n",
    "    print(\n",
    "        f\"{s:15s} | exact: {str(ex):5s} | approximate: {str(app):5s} | maxdiff: {maxdiff}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "490fdcfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4137\n"
     ]
    }
   ],
   "source": [
    "n_embd = 10  # the dimensionality of the character embedding vectors\n",
    "n_hidden = 64  # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647)  # for reproducibility\n",
    "C = torch.randn((vocab_size, n_embd), generator=g)\n",
    "# layer 1\n",
    "W1 = (\n",
    "    torch.randn((n_embd * block_size, n_hidden), generator=g)\n",
    "    * (5 / 3)\n",
    "    / ((n_embd * block_size) ** 0.5)\n",
    ")\n",
    "b1 = (\n",
    "    torch.randn(n_hidden, generator=g) * 0.1\n",
    ")  # using b1 just for fun, it's useless because of BN\n",
    "# layer 2\n",
    "W2 = torch.randn((n_hidden, vocab_size), generator=g) * 0.1\n",
    "b2 = torch.randn(vocab_size, generator=g) * 0.1\n",
    "# batchnorm parameters\n",
    "bngain = torch.randn((1, n_hidden)) * 0.1 + 1.0\n",
    "bnbias = torch.randn((1, n_hidden)) * 0.1\n",
    "\n",
    "# note: i am initializating many of these parameters (e.g., biases) in non-standard ways\n",
    "# because sometimes initializating with e.g. all zeros could mask an incorrect\n",
    "# implementation of the backward pass\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters))  # number of parameters in total\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08cf080a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "n = batch_size  # a shorter variable also, for convenience\n",
    "# construct a minibatch\n",
    "ix = torch.randint(0, x_trn.shape[0], (batch_size,), generator=g)\n",
    "xb, yb = x_trn[ix], y_trn[ix]  # batch X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "512bdf93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.3591, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forward pass, \"chunkated\" into smaller steps that are possible to backward one at a time\n",
    "\n",
    "emb = C[xb]  # embed the characters into vectors\n",
    "embcat = emb.view(emb.shape[0], -1)  # concatenate the vectors\n",
    "# linear layer 1\n",
    "hprebn = embcat @ W1 + b1  # hidden layer pre-activation\n",
    "# batchnorm layer\n",
    "bnmeani = 1 / n * hprebn.sum(0, keepdim=True)\n",
    "bndiff = hprebn - bnmeani\n",
    "bndiff2 = bndiff**2\n",
    "bnvar = (\n",
    "    1 / (n - 1) * (bndiff2).sum(0, keepdim=True)\n",
    ")  # note: Bessel's correction (dividing by n-1, not n)\n",
    "bnvar_inv = (bnvar + 1e-5) ** -0.5\n",
    "bnraw = bndiff * bnvar_inv\n",
    "hpreact = bngain * bnraw + bnbias\n",
    "# non-linearity\n",
    "h = torch.tanh(hpreact)  # hidden layer\n",
    "# linear layer 2\n",
    "logits = h @ W2 + b2  # output layer\n",
    "# cross entropy loss (same as F.cross_entropy(logits, yb))\n",
    "logit_maxes = logits.max(1, keepdim=True).values\n",
    "norm_logits = logits - logit_maxes  # subtract max for numerical stability\n",
    "counts = norm_logits.exp()\n",
    "counts_sum = counts.sum(1, keepdims=True)\n",
    "counts_sum_inv = (\n",
    "    counts_sum**-1\n",
    ")  # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n",
    "probs = counts * counts_sum_inv\n",
    "logprobs = probs.log()\n",
    "loss = -logprobs[range(n), yb].mean()\n",
    "\n",
    "# PyTorch backward pass\n",
    "for p in parameters:\n",
    "    p.grad = None\n",
    "\n",
    "for t in [\n",
    "    logprobs,\n",
    "    probs,\n",
    "    counts,\n",
    "    counts_sum,\n",
    "    counts_sum_inv,  # afaik there is no cleaner way\n",
    "    norm_logits,\n",
    "    logit_maxes,\n",
    "    logits,\n",
    "    h,\n",
    "    hpreact,\n",
    "    bnraw,\n",
    "    bnvar_inv,\n",
    "    bnvar,\n",
    "    bndiff2,\n",
    "    bndiff,\n",
    "    hprebn,\n",
    "    bnmeani,\n",
    "    embcat,\n",
    "    emb,\n",
    "]:\n",
    "    t.retain_grad()\n",
    "loss.backward()\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e209666",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "Backprop through the whole thing manually, backpropagating through exactly all of the variables as they are defined in the forward pass above, one by one.\n",
    "\n",
    "A few notes before we start:\n",
    "* As a naming convention, we are going to name each variable storing the partial derivative of the loss w.r.t. each parameter group, `d` + `<parameter group>`. For instance, the partial derivative of the loss w.r.t. `logprobs`, $ \\frac{\\partial J(w, b)}{\\partial \\text{logprobs}} $, will be named `dlogprobs`.\n",
    "* We are also omitting $ \\frac{\\partial J(w, b)}{\\partial J(w, b} $ as that is equal to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad5629c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprobs        | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "probs           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts_sum_inv  | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts_sum      | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "norm_logits     | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "logit_maxes     | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "logits          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "h               | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "W2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "b2              | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# create a matrix of all zero of the same shape as the `logprobs` array, to store the \n",
    "# gradients `dlogprobs` \n",
    "dlogprobs = torch.zeros_like(logprobs)\n",
    "# update the gradient only of the elements corresponding to the ground truth predictions \n",
    "# with the partial derivative of the loss w.r.t. logprobs\n",
    "dlogprobs[range(n), yb] = -1.0 / n\n",
    "cmp(\"logprobs\", dlogprobs, logprobs)\n",
    "\n",
    "dprobs = (1.0 / probs) * dlogprobs # multiply by dlogprobs as we are using the chain rule\n",
    "cmp(\"probs\", dprobs, probs)\n",
    "\n",
    "# in this case, we need to keep in mind that `counts`, `dprobs`, and `count_sum_inv` have\n",
    "# different shapes:\n",
    "# >>> counts.shape, dprobs.shape, counts_sum_inv.shape\n",
    "# (torch.Size([32, 27]), torch.Size([32, 27])), torch.Size([32, 1])) \n",
    "# we need `dcounts_sum_inv` to be of shape (32, 1), thus accumulating the gradients of \n",
    "# each row\n",
    "# d11 d12 d13     b1 (= d11 + d12 + d13)\n",
    "# d21 d22 d23 --> b2 (= d21 + d22 + d23)\n",
    "# d31 d32 d33     b3 (= d31 + d32 + d33)\n",
    "dcounts_sum_inv = (counts * dprobs).sum(1, keepdims=True)\n",
    "cmp(\"counts_sum_inv\", dcounts_sum_inv, counts_sum_inv)\n",
    "\n",
    "# `dcounts` is a trickier example, as `counts` is used in two places in the computational\n",
    "# graph:\n",
    "# 1. probs = counts * counts_sum_inv, AND...\n",
    "# 2. counts_sum = counts.sum(1, keepdims=True)\n",
    "# we are going to work initially on the first contribution, and later add the second part \n",
    "# to it to compute the total gradient\n",
    "dcounts = counts_sum_inv * dprobs\n",
    "\n",
    "dcounts_sum = (-counts_sum ** -2) * dcounts_sum_inv\n",
    "cmp(\"counts_sum\", dcounts_sum, counts_sum)\n",
    "\n",
    "# let's now resume working on `dcounts` by processing the second contribution:\n",
    "# `counts_sum = counts.sum(1, keepdims=True)`\n",
    "# also in this case, we need to keep an eye on the dimension of the variables:\n",
    "# >>> counts.shape, dcounts_sum.shape\n",
    "# (torch.Size([32, 27]), torch.Size([32, 1]))\n",
    "# what we want to accomplish is to add to all elements in `dcounts` the `dcounts_sum`\n",
    "# contribution. since `dcounts_sum`\n",
    "# a11 a12 a13   b1 --> a11 a12 a13   b1 b1 b1    \n",
    "# a21 a22 a23 + b2 --> a21 a22 a23 + b2 b2 b2  \n",
    "# a31 a32 a33   b3 --> a31 a32 a33   b3 b3 b3    \n",
    "# this is a simple broadcasting operation, where `dcounts_sum` expands from (32, 1) \n",
    "# to (32, 27)\n",
    "# NOTE: karpathy implements it in a slightly move convoluted way:\n",
    "# >>> dcounts += torch.ones_like(counts) * dcounts_sum \n",
    "dcounts += dcounts_sum # the += operation is because we are summing the contribution of both branches\n",
    "cmp('counts', dcounts, counts)\n",
    "# NOTE: the max() operation fans out the gradient to all elements of the activations that were\n",
    "# included in the operation equally! >>> risk of accidental gradient explosion??\n",
    "\n",
    "dnorm_logits = counts * dcounts  # counts = norm_logits.exp(); in this way we save some FLOPs :-)\n",
    "cmp('norm_logits', dnorm_logits, norm_logits)\n",
    "\n",
    "# `logits` is used in two places in the computational graph:\n",
    "# >>> logit_maxes = logits.max(1, keepdim=True).values\n",
    "# >>> norm_logits = logits - logit_maxes  # subtract max for numerical stability\n",
    "# the shape of `logits` and `logit_maxes` is not the same, as there is an implicit \n",
    "# broadcasting operation in the `logits - logit_maxes` operation:\n",
    "# >>> logits.shape, logit_maxes.shape\n",
    "# (torch.Size([32, 27]), torch.Size([32, 1]))\n",
    "# `logit_maxes` is broadcasted from (32, 1) to (32, 27) \n",
    "# c11 c12 c13   a11 a12 a13   c11\n",
    "# c21 c22 c23 = a21 a22 a23 - c21\n",
    "# c31 c32 c33   a31 a32 a33   c31\n",
    "dlogits = dnorm_logits.clone()  # 1st contribution\n",
    "\n",
    "dlogit_maxes = (-dnorm_logits).sum(1, keepdims=True)\n",
    "cmp('logit_maxes', dlogit_maxes, logit_maxes)\n",
    "if not torch.allclose(dlogit_maxes, torch.zeros_like(dlogit_maxes)):\n",
    "    # NOTE: `dlogit_maxes` should be very close to 0, because that offset we use to normalize the logit vector before passing it to torch.exp()\n",
    "    # should have no impact on the loss! In fact, we could have used any constant to normalize the logit vector without impacting the value of\n",
    "    # loss. The only reason why we are using max() is to guarantee that the max value of the \"normalized\" logit vector before passing it to \n",
    "    # torch.exp() is zero, to avoid any potential overflow.\n",
    "    print(\"Error: some elements of `dlogit_maxes` are not close to zero!\")\n",
    "\n",
    "# here we want the derivative to flow through where those maximum values occurred in the logit vector\n",
    "# NOTE: karphathy implements it with a different syntax, but the outcome is the same:\n",
    "# >>> dlogits += F.one_hot(logits.max(1).indices, num_classes=logits.shape[1]) * dlogit_maxes\n",
    "dlogits[range(n), logits.max(1).indices] += dlogit_maxes.view(-1, )  # 2nd contribution\n",
    "cmp('logits', dlogits, logits)\n",
    "\n",
    "# see notes in reMarkable for the full manual derivation\n",
    "dh = dlogits @ W2.T\n",
    "dW2 = h.T @ dlogits\n",
    "db2 = dlogits.sum(0)\n",
    "cmp('h', dh, h)\n",
    "cmp('W2', dW2, W2)\n",
    "cmp('b2', db2, b2)\n",
    "\n",
    "# cmp('hpreact', dhpreact, hpreact)\n",
    "# cmp('bngain', dbngain, bngain)\n",
    "# cmp('bnbias', dbnbias, bnbias)\n",
    "# cmp('bnraw', dbnraw, bnraw)\n",
    "# cmp('bnvar_inv', dbnvar_inv, bnvar_inv)\n",
    "# cmp('bnvar', dbnvar, bnvar)\n",
    "# cmp('bndiff2', dbndiff2, bndiff2)\n",
    "# cmp('bndiff', dbndiff, bndiff)\n",
    "# cmp('bnmeani', dbnmeani, bnmeani)\n",
    "# cmp('hprebn', dhprebn, hprebn)\n",
    "# cmp('embcat', dembcat, embcat)\n",
    "# cmp('W1', dW1, W1)\n",
    "# cmp('b1', db1, b1)\n",
    "# cmp('emb', demb, emb)\n",
    "# cmp('C', dC, C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f359b516",
   "metadata": {},
   "source": [
    "NOTES:\n",
    "1. The parameter group and the derivative of the loss w.r.t. that parameter group must have the same shape.\n",
    "1. If a parameter group is used multiple branches of the computational graph, we must accumulate the gradient of both branches.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8790365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 27]),\n",
       " torch.Size([32, 64]),\n",
       " torch.Size([64, 27]),\n",
       " torch.Size([27]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogits.shape, h.shape, W2.shape, b2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae078481",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
