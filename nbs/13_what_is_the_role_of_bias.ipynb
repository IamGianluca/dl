{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bc99ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d388ae5",
   "metadata": {},
   "source": [
    "## What is the role of the bias term in a neural network?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196ccdb4",
   "metadata": {},
   "source": [
    "Let's build a very simple linear layer, that can optionally take a bias term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75090b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear(x, w, b=None, debug=False):\n",
    "    if b is not None:\n",
    "        a = (x @ w) + b\n",
    "    else:\n",
    "        a = (x @ w)\n",
    "    if debug:\n",
    "        print(a.shape)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4161e97c",
   "metadata": {},
   "source": [
    "### Forward pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af335e7",
   "metadata": {},
   "source": [
    "If we stack a few instances of this linear layer, the mean of the feature map computed after approximately 44 layers will have a mean and std equal to `nan`. This is called activation explosion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "634a6820",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs, m = 1, 28 * 28\n",
    "nh = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22ec4042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.0243) tensor(26.1706)\n",
      "tensor(-9.6323) tensor(188.7720)\n",
      "tensor(-575.9617) tensor(1162.1053)\n",
      "tensor(-1039.7336) tensor(10019.8301)\n",
      "tensor(-10346.8691) tensor(63094.7305)\n",
      "tensor(-8526.0703) tensor(455544.7500)\n",
      "tensor(-1102988.1250) tensor(3361917.5000)\n",
      "tensor(227481.6875) tensor(25106340.)\n",
      "tensor(32292486.) tensor(1.8682e+08)\n",
      "tensor(2.2850e+08) tensor(1.3495e+09)\n",
      "tensor(-1.2376e+09) tensor(9.3639e+09)\n",
      "tensor(7.4606e+09) tensor(6.4331e+10)\n",
      "tensor(-5.6087e+10) tensor(4.3354e+11)\n",
      "tensor(-5.9011e+11) tensor(2.6942e+12)\n",
      "tensor(-2.8687e+12) tensor(1.8670e+13)\n",
      "tensor(1.6036e+13) tensor(1.3257e+14)\n",
      "tensor(-9.9115e+12) tensor(9.5434e+14)\n",
      "tensor(-1.4960e+15) tensor(6.2041e+15)\n",
      "tensor(-4.5607e+15) tensor(3.8465e+16)\n",
      "tensor(-5.3774e+16) tensor(1.9924e+17)\n",
      "tensor(9.8150e+16) tensor(1.4602e+18)\n",
      "tensor(3.1619e+17) tensor(1.0735e+19)\n",
      "tensor(-1.4530e+19) tensor(6.6974e+19)\n",
      "tensor(-3.5854e+19) tensor(4.8939e+20)\n",
      "tensor(1.5195e+20) tensor(3.6402e+21)\n",
      "tensor(-2.6961e+21) tensor(2.4501e+22)\n",
      "tensor(4.1128e+21) tensor(1.9594e+23)\n",
      "tensor(-1.3505e+23) tensor(1.2021e+24)\n",
      "tensor(1.2100e+24) tensor(8.0784e+24)\n",
      "tensor(4.8519e+24) tensor(5.9360e+25)\n",
      "tensor(-7.9763e+25) tensor(3.9416e+26)\n",
      "tensor(2.5644e+26) tensor(2.8527e+27)\n",
      "tensor(1.1682e+27) tensor(1.9872e+28)\n",
      "tensor(-5.5457e+27) tensor(1.2479e+29)\n",
      "tensor(7.5116e+28) tensor(7.7668e+29)\n",
      "tensor(-9.2780e+29) tensor(5.5214e+30)\n",
      "tensor(5.8383e+30) tensor(4.1033e+31)\n",
      "tensor(-1.7461e+31) tensor(3.0995e+32)\n",
      "tensor(-2.7559e+32) tensor(2.4802e+33)\n",
      "tensor(-6.3178e+32) tensor(1.5753e+34)\n",
      "tensor(2.5377e+34) tensor(1.0839e+35)\n",
      "tensor(4.4080e+34) tensor(7.2516e+35)\n",
      "tensor(-1.0456e+35) tensor(5.2329e+36)\n",
      "tensor(-inf) tensor(inf)\n",
      "Numerical instability at layer 43\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(bs, m)  # input image\n",
    "\n",
    "for i in range(100): \n",
    "    w = torch.randn(m, nh) if i == 0 else torch.randn(nh, nh)\n",
    "    \n",
    "    a = linear(a, w)\n",
    "    print(a.mean(), a.std())\n",
    "    \n",
    "    if torch.isinf(a.std()) or torch.isnan(a.std()):\n",
    "        print(f\"Numerical instability at layer {i}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4672d7",
   "metadata": {},
   "source": [
    "Adding a bias term, unfortunately does not help in keeping the variance more numerically stable, and therefore does not seem to help in training deeper networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30bf681e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-4.1558) tensor(22.5135)\n",
      "tensor(-12.7045) tensor(157.3415)\n",
      "tensor(116.9325) tensor(1014.1555)\n",
      "tensor(165.3409) tensor(6892.7690)\n",
      "tensor(2628.7520) tensor(42421.7539)\n",
      "tensor(48158.7344) tensor(311417.0938)\n",
      "tensor(-378727.4375) tensor(2563695.5000)\n",
      "tensor(3641287.7500) tensor(17689588.)\n",
      "tensor(-13041480.) tensor(1.3575e+08)\n",
      "tensor(1.2193e+08) tensor(1.0693e+09)\n",
      "tensor(-1.2086e+09) tensor(7.3240e+09)\n",
      "tensor(1.0753e+10) tensor(4.7974e+10)\n",
      "tensor(-1.1516e+11) tensor(3.2171e+11)\n",
      "tensor(8.1565e+10) tensor(2.3479e+12)\n",
      "tensor(2.8885e+12) tensor(1.6541e+13)\n",
      "tensor(1.0997e+13) tensor(1.2849e+14)\n",
      "tensor(7.0010e+13) tensor(9.0753e+14)\n",
      "tensor(-2.8257e+14) tensor(5.6709e+15)\n",
      "tensor(1.5141e+15) tensor(3.5614e+16)\n",
      "tensor(4.9815e+15) tensor(2.2148e+17)\n",
      "tensor(1.4019e+17) tensor(1.4494e+18)\n",
      "tensor(9.9039e+17) tensor(9.9376e+18)\n",
      "tensor(-2.6426e+19) tensor(6.0428e+19)\n",
      "tensor(-3.5399e+18) tensor(4.4832e+20)\n",
      "tensor(-2.8904e+20) tensor(3.0153e+21)\n",
      "tensor(3.1508e+21) tensor(2.2223e+22)\n",
      "tensor(5.3199e+21) tensor(1.4949e+23)\n",
      "tensor(2.3649e+23) tensor(1.0456e+24)\n",
      "tensor(-3.3052e+23) tensor(6.4933e+24)\n",
      "tensor(-6.0397e+23) tensor(3.9821e+25)\n",
      "tensor(4.3607e+24) tensor(3.0054e+26)\n",
      "tensor(-3.3655e+26) tensor(2.2093e+27)\n",
      "tensor(-1.1731e+27) tensor(1.6200e+28)\n",
      "tensor(-2.0031e+28) tensor(1.1320e+29)\n",
      "tensor(-8.5174e+28) tensor(7.4737e+29)\n",
      "tensor(9.6814e+29) tensor(4.6225e+30)\n",
      "tensor(-8.1465e+30) tensor(3.1977e+31)\n",
      "tensor(3.2927e+31) tensor(2.4155e+32)\n",
      "tensor(3.4387e+29) tensor(1.8714e+33)\n",
      "tensor(-2.5841e+33) tensor(1.1932e+34)\n",
      "tensor(1.8265e+33) tensor(8.2145e+34)\n",
      "tensor(6.6978e+33) tensor(4.9288e+35)\n",
      "tensor(-6.8172e+34) tensor(4.0403e+36)\n",
      "tensor(1.2945e+36) tensor(2.7304e+37)\n",
      "tensor(nan) tensor(nan)\n",
      "Numerical instability at layer 44\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(bs, m)  # input image\n",
    "\n",
    "for i in range(100): \n",
    "    w = torch.randn(m, nh) if i == 0 else torch.randn(nh, nh)\n",
    "    b = torch.randn(nh)\n",
    "\n",
    "    a = linear(a, w, b)\n",
    "    print(a.mean(), a.std())\n",
    "    if torch.isinf(a.std()) or torch.isnan(a.std()):\n",
    "        print(f\"Numerical instability at layer {i}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a660a06",
   "metadata": {},
   "source": [
    "Note, however, how the mean and std of the feature maps generated by every layer are still very large. This network, despite being deeper, will not be able to learn much."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4f0491",
   "metadata": {},
   "source": [
    "### Is a good init sufficient to fix the issue?\n",
    "\n",
    "Improving the init, completely fixes the activation explosion issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b45400c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3566) tensor(1.3213)\n",
      "tensor(-0.1118) tensor(0.9710)\n",
      "tensor(-0.0071) tensor(1.0783)\n",
      "tensor(-0.0314) tensor(1.1460)\n",
      "tensor(0.1210) tensor(0.9311)\n",
      "tensor(0.1114) tensor(1.1002)\n",
      "tensor(-0.2043) tensor(1.0311)\n",
      "tensor(-0.0843) tensor(1.0027)\n",
      "tensor(-0.0686) tensor(1.1469)\n",
      "tensor(0.1537) tensor(1.0446)\n",
      "tensor(-0.1908) tensor(1.0336)\n",
      "tensor(0.0104) tensor(1.1801)\n",
      "tensor(0.0464) tensor(1.0580)\n",
      "tensor(0.3212) tensor(1.1358)\n",
      "tensor(0.2729) tensor(1.0590)\n",
      "tensor(-0.1149) tensor(0.8153)\n",
      "tensor(-0.0500) tensor(0.9828)\n",
      "tensor(-0.0392) tensor(0.9944)\n",
      "tensor(0.0926) tensor(0.9233)\n",
      "tensor(-0.2271) tensor(1.0482)\n",
      "tensor(-0.2560) tensor(1.0281)\n",
      "tensor(0.2026) tensor(1.2260)\n",
      "tensor(0.0484) tensor(1.1781)\n",
      "tensor(-0.1618) tensor(1.1089)\n",
      "tensor(0.0450) tensor(1.2104)\n",
      "tensor(-0.2285) tensor(1.0585)\n",
      "tensor(-0.1079) tensor(1.0125)\n",
      "tensor(0.0939) tensor(0.9085)\n",
      "tensor(0.1066) tensor(0.9092)\n",
      "tensor(-0.3181) tensor(0.9785)\n",
      "tensor(0.3183) tensor(0.9863)\n",
      "tensor(0.2722) tensor(0.8722)\n",
      "tensor(-0.2136) tensor(0.8379)\n",
      "tensor(-0.0492) tensor(1.0109)\n",
      "tensor(-0.0596) tensor(1.2265)\n",
      "tensor(0.0638) tensor(0.9741)\n",
      "tensor(-0.2204) tensor(1.1283)\n",
      "tensor(0.1707) tensor(0.9472)\n",
      "tensor(0.0905) tensor(1.0738)\n",
      "tensor(-0.1441) tensor(1.0233)\n",
      "tensor(-0.0966) tensor(1.0141)\n",
      "tensor(-0.0797) tensor(1.0327)\n",
      "tensor(-0.1628) tensor(1.0484)\n",
      "tensor(-0.0587) tensor(0.7863)\n",
      "tensor(-0.1656) tensor(0.7849)\n",
      "tensor(0.1516) tensor(1.0234)\n",
      "tensor(0.0275) tensor(0.9538)\n",
      "tensor(0.2166) tensor(0.8987)\n",
      "tensor(0.0908) tensor(1.0706)\n",
      "tensor(0.0507) tensor(0.9907)\n",
      "tensor(-0.0121) tensor(1.0829)\n",
      "tensor(-0.0221) tensor(1.0530)\n",
      "tensor(0.1872) tensor(1.1368)\n",
      "tensor(-0.0322) tensor(1.1217)\n",
      "tensor(-0.2796) tensor(1.0752)\n",
      "tensor(0.1415) tensor(0.9050)\n",
      "tensor(-0.1278) tensor(1.0753)\n",
      "tensor(-0.1161) tensor(1.0255)\n",
      "tensor(-0.1629) tensor(0.8575)\n",
      "tensor(-0.3236) tensor(1.1348)\n",
      "tensor(-0.2233) tensor(0.9360)\n",
      "tensor(0.1194) tensor(1.0798)\n",
      "tensor(-0.1136) tensor(1.1972)\n",
      "tensor(-0.0134) tensor(1.0549)\n",
      "tensor(0.2384) tensor(1.0252)\n",
      "tensor(-0.0016) tensor(0.9505)\n",
      "tensor(-0.0402) tensor(1.0840)\n",
      "tensor(-0.1489) tensor(1.0089)\n",
      "tensor(0.0952) tensor(1.2132)\n",
      "tensor(-0.1362) tensor(1.2486)\n",
      "tensor(-0.1496) tensor(1.1400)\n",
      "tensor(0.2095) tensor(1.1462)\n",
      "tensor(0.0093) tensor(1.0160)\n",
      "tensor(-0.0667) tensor(1.1487)\n",
      "tensor(-0.2025) tensor(0.7977)\n",
      "tensor(0.0578) tensor(0.8837)\n",
      "tensor(-0.0345) tensor(1.1873)\n",
      "tensor(-0.2563) tensor(0.9951)\n",
      "tensor(0.0518) tensor(0.9330)\n",
      "tensor(0.1918) tensor(1.1549)\n",
      "tensor(0.1050) tensor(0.9215)\n",
      "tensor(0.1340) tensor(0.9747)\n",
      "tensor(0.0024) tensor(0.8613)\n",
      "tensor(0.2167) tensor(0.9486)\n",
      "tensor(-0.1028) tensor(0.9314)\n",
      "tensor(0.0366) tensor(1.1711)\n",
      "tensor(-0.1245) tensor(1.0161)\n",
      "tensor(-0.1493) tensor(1.0002)\n",
      "tensor(-0.2112) tensor(0.9779)\n",
      "tensor(-0.0346) tensor(1.1157)\n",
      "tensor(0.1350) tensor(1.0646)\n",
      "tensor(-0.0889) tensor(1.0060)\n",
      "tensor(0.2089) tensor(1.0294)\n",
      "tensor(0.0732) tensor(0.8524)\n",
      "tensor(-0.1617) tensor(1.0929)\n",
      "tensor(0.1373) tensor(1.2199)\n",
      "tensor(0.1581) tensor(0.9769)\n",
      "tensor(-0.0365) tensor(1.1419)\n",
      "tensor(-0.0681) tensor(1.0962)\n",
      "tensor(-0.1456) tensor(1.1061)\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(bs, m)  # input image\n",
    "\n",
    "for i in range(100): \n",
    "    w = torch.randn(m, nh) / math.sqrt(m) if i == 0 else torch.randn(nh, nh) / math.sqrt(m)  # xavier init\n",
    "    b = torch.randn(nh)\n",
    "\n",
    "    a = linear(a, w, b)\n",
    "    print(a.mean(), a.std())\n",
    "    if torch.isinf(a.std()) or torch.isnan(a.std()):\n",
    "        print(f\"Numerical instability at layer {i}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932ae9c6",
   "metadata": {},
   "source": [
    "Let's do an ablation study and try Xavier init without using the bias term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cce21e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.2671) tensor(0.9502)\n",
      "tensor(-0.0076) tensor(0.2757)\n",
      "tensor(0.0101) tensor(0.0723)\n",
      "tensor(0.0038) tensor(0.0186)\n",
      "tensor(0.0007) tensor(0.0047)\n",
      "tensor(5.4310e-05) tensor(0.0011)\n",
      "tensor(1.4506e-05) tensor(0.0003)\n",
      "tensor(1.5759e-05) tensor(7.7497e-05)\n",
      "tensor(8.5075e-07) tensor(1.9835e-05)\n",
      "tensor(-9.8762e-08) tensor(5.0685e-06)\n",
      "tensor(6.1725e-08) tensor(1.2090e-06)\n",
      "tensor(4.8311e-08) tensor(2.6407e-07)\n",
      "tensor(-1.4101e-09) tensor(6.7252e-08)\n",
      "tensor(-1.8381e-09) tensor(1.4054e-08)\n",
      "tensor(-4.8925e-10) tensor(3.3937e-09)\n",
      "tensor(-5.0788e-11) tensor(7.8351e-10)\n",
      "tensor(1.5469e-11) tensor(1.8582e-10)\n",
      "tensor(-1.8344e-12) tensor(5.6959e-11)\n",
      "tensor(1.2314e-12) tensor(1.6890e-11)\n",
      "tensor(1.0745e-13) tensor(3.9216e-12)\n",
      "tensor(-1.0743e-14) tensor(8.8020e-13)\n",
      "tensor(7.0873e-14) tensor(2.2054e-13)\n",
      "tensor(-3.0059e-15) tensor(6.0513e-14)\n",
      "tensor(4.1854e-15) tensor(1.4695e-14)\n",
      "tensor(-1.1109e-15) tensor(3.8098e-15)\n",
      "tensor(-4.4225e-17) tensor(9.7716e-16)\n",
      "tensor(4.2663e-17) tensor(2.5967e-16)\n",
      "tensor(-1.6264e-17) tensor(6.6367e-17)\n",
      "tensor(1.4606e-18) tensor(1.5916e-17)\n",
      "tensor(7.5770e-19) tensor(4.2319e-18)\n",
      "tensor(-1.5560e-19) tensor(1.1281e-18)\n",
      "tensor(-1.8379e-21) tensor(2.7269e-19)\n",
      "tensor(1.1506e-20) tensor(7.7773e-20)\n",
      "tensor(2.2062e-21) tensor(1.8032e-20)\n",
      "tensor(3.5029e-22) tensor(3.8878e-21)\n",
      "tensor(-2.3885e-22) tensor(8.1302e-22)\n",
      "tensor(-4.2183e-25) tensor(2.0522e-22)\n",
      "tensor(-4.5855e-24) tensor(5.4654e-23)\n",
      "tensor(3.5209e-24) tensor(1.4308e-23)\n",
      "tensor(1.1591e-24) tensor(3.5138e-24)\n",
      "tensor(-4.4468e-26) tensor(1.0523e-24)\n",
      "tensor(-3.7606e-26) tensor(3.0115e-25)\n",
      "tensor(9.9741e-27) tensor(6.9424e-26)\n",
      "tensor(2.3569e-27) tensor(1.5262e-26)\n",
      "tensor(-3.6816e-28) tensor(4.4888e-27)\n",
      "tensor(1.5782e-28) tensor(1.2297e-27)\n",
      "tensor(-9.2679e-29) tensor(3.0660e-28)\n",
      "tensor(1.0214e-29) tensor(8.0184e-29)\n",
      "tensor(-4.6686e-30) tensor(2.1664e-29)\n",
      "tensor(-5.7191e-31) tensor(5.3897e-30)\n",
      "tensor(-1.1719e-31) tensor(1.3940e-30)\n",
      "tensor(-1.3564e-32) tensor(3.4953e-31)\n",
      "tensor(-2.1816e-33) tensor(7.8177e-32)\n",
      "tensor(1.5185e-33) tensor(1.9353e-32)\n",
      "tensor(-1.1950e-33) tensor(4.7157e-33)\n",
      "tensor(3.5773e-34) tensor(9.5670e-34)\n",
      "tensor(-2.0488e-35) tensor(2.8723e-34)\n",
      "tensor(3.7703e-36) tensor(6.7087e-35)\n",
      "tensor(2.2150e-36) tensor(1.5539e-35)\n",
      "tensor(3.1376e-37) tensor(3.8828e-36)\n",
      "tensor(2.9136e-38) tensor(9.0807e-37)\n",
      "tensor(1.5483e-38) tensor(2.1129e-37)\n",
      "tensor(2.5525e-39) tensor(5.9688e-38)\n",
      "tensor(-4.2100e-39) tensor(1.3890e-38)\n",
      "tensor(5.7120e-40) tensor(3.2474e-39)\n",
      "tensor(-4.8219e-42) tensor(9.0339e-40)\n",
      "tensor(6.2354e-41) tensor(1.8540e-40)\n",
      "tensor(-1.5177e-41) tensor(5.1185e-41)\n",
      "tensor(-1.4475e-42) tensor(1.5287e-41)\n",
      "tensor(-1.2612e-44) tensor(3.7863e-42)\n",
      "tensor(1.3452e-43) tensor(8.6740e-43)\n",
      "tensor(-2.9427e-44) tensor(2.1440e-43)\n",
      "tensor(2.8026e-45) tensor(6.0256e-44)\n",
      "tensor(-1.4013e-45) tensor(1.4013e-44)\n",
      "tensor(-0.) tensor(2.8026e-45)\n",
      "tensor(0.) tensor(0.)\n",
      "tensor(0.) tensor(0.)\n",
      "tensor(0.) tensor(0.)\n",
      "tensor(0.) tensor(0.)\n",
      "tensor(0.) tensor(0.)\n",
      "tensor(0.) tensor(0.)\n",
      "tensor(0.) tensor(0.)\n",
      "tensor(0.) tensor(0.)\n",
      "tensor(0.) tensor(0.)\n",
      "tensor(0.) tensor(0.)\n",
      "tensor(0.) tensor(0.)\n",
      "tensor(0.) tensor(0.)\n",
      "tensor(0.) tensor(0.)\n",
      "tensor(0.) tensor(0.)\n",
      "tensor(0.) tensor(0.)\n",
      "tensor(0.) tensor(0.)\n",
      "tensor(0.) tensor(0.)\n",
      "tensor(0.) tensor(0.)\n",
      "tensor(0.) tensor(0.)\n",
      "tensor(0.) tensor(0.)\n",
      "tensor(0.) tensor(0.)\n",
      "tensor(0.) tensor(0.)\n",
      "tensor(0.) tensor(0.)\n",
      "tensor(0.) tensor(0.)\n",
      "tensor(0.) tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(bs, m)  # input image\n",
    "\n",
    "for i in range(100): \n",
    "    w = torch.randn(m, nh) / math.sqrt(m) if i == 0 else torch.randn(nh, nh) / math.sqrt(m)\n",
    "\n",
    "    a = linear(a, w)\n",
    "    print(a.mean(), a.std())\n",
    "    if torch.isinf(a.std()) or torch.isnan(a.std()):\n",
    "        print(f\"Numerical instability at layer {i}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d74e40a",
   "metadata": {},
   "source": [
    "Removing the bias term shows that just a good init is not enough. The purpose of the bias term is to improve numerical stability in the forward pass. Without a bias term, it is harder to train deep architectures.\n",
    "\n",
    "In each layer of the forward pass, we are multiplying the previous layer's output activation by a set of weights close to zero. Repeating this step multiple times will lead to a set of output activation with a std so small that it clamps to `nan`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb69d079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.01, 0.0001, 1.0000000000000002e-06)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 * 0.01, 1 * 0.01 * 0.01, 1 * 0.01 * 0.01 * 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa2b908",
   "metadata": {},
   "source": [
    "### TODO\n",
    "\n",
    "- [ ] Does Xavier init make any assumption about the bias term?\n",
    "- [ ] Plot activations for each layer\n",
    "- [ ] Backward pass\n",
    "- [ ] BatchNorm\n",
    "- [ ] ReLu\n",
    "- [ ] Conv layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e5f2bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
