{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0fd163e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07e9c47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f036b8f4",
   "metadata": {},
   "source": [
    "## What is the role of the bias term in a neural network?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1dbfedc",
   "metadata": {},
   "source": [
    "Let's build a very simple linear layer, that can optionally take a bias term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe86b736",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin(x, w, b=None, debug=False):\n",
    "    if b is not None:\n",
    "        a = (x @ w) + b\n",
    "    else:\n",
    "        a = (x @ w)\n",
    "    if debug:\n",
    "        print(a.shape)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61305147",
   "metadata": {},
   "source": [
    "### Forward pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623dc5b1",
   "metadata": {},
   "source": [
    "If we stack a few instances of this linear layer, the mean of the feature map computed after just two layers will have a mean very far from zero and inf/nan std. This is called activation explosion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "755e7348",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs, m = 1, 28*28\n",
    "nh = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5076dd16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1.6022) tensor(32.2359)\n",
      "tensor(25.5023) tensor(194.1806)\n",
      "tensor(133.4860) tensor(1383.7087)\n",
      "tensor(1224.4739) tensor(8681.0977)\n",
      "tensor(-17732.4043) tensor(67681.3516)\n",
      "tensor(429.2725) tensor(521368.6875)\n",
      "tensor(-34658.0195) tensor(3407623.)\n",
      "tensor(8298728.5000) tensor(27529012.)\n",
      "tensor(15308513.) tensor(1.9155e+08)\n",
      "tensor(-4.4268e+08) tensor(1.5578e+09)\n",
      "tensor(-6.2623e+08) tensor(9.4120e+09)\n",
      "tensor(-2.0260e+09) tensor(6.2145e+10)\n",
      "tensor(5.8645e+10) tensor(3.9950e+11)\n",
      "tensor(-1.0380e+11) tensor(2.5730e+12)\n",
      "tensor(2.1449e+12) tensor(1.7724e+13)\n",
      "tensor(-3.0679e+12) tensor(1.0827e+14)\n",
      "tensor(7.2502e+13) tensor(7.6339e+14)\n",
      "tensor(4.9434e+13) tensor(5.3466e+15)\n",
      "tensor(-2.7428e+15) tensor(3.8353e+16)\n",
      "tensor(2.5686e+16) tensor(2.3944e+17)\n",
      "tensor(7.3178e+16) tensor(1.8415e+18)\n",
      "tensor(4.2566e+16) tensor(1.2829e+19)\n",
      "tensor(-8.2446e+17) tensor(8.3547e+19)\n",
      "tensor(1.3131e+19) tensor(6.9450e+20)\n",
      "tensor(-4.0995e+19) tensor(5.1958e+21)\n",
      "tensor(-5.8406e+21) tensor(3.6376e+22)\n",
      "tensor(-2.1548e+22) tensor(2.1999e+23)\n",
      "tensor(-2.0261e+22) tensor(1.7313e+24)\n",
      "tensor(5.4965e+23) tensor(1.1603e+25)\n",
      "tensor(-3.0745e+23) tensor(8.8949e+25)\n",
      "tensor(9.4573e+25) tensor(6.5230e+26)\n",
      "tensor(7.3563e+26) tensor(4.6052e+27)\n",
      "tensor(-8.4086e+27) tensor(3.3965e+28)\n",
      "tensor(-2.5375e+28) tensor(2.6343e+29)\n",
      "tensor(4.2064e+28) tensor(1.6662e+30)\n",
      "tensor(7.3335e+29) tensor(1.1720e+31)\n",
      "tensor(1.0195e+31) tensor(9.5432e+31)\n",
      "tensor(-5.1362e+31) tensor(6.7088e+32)\n",
      "tensor(1.6286e+32) tensor(5.5692e+33)\n",
      "tensor(-3.5509e+33) tensor(3.6062e+34)\n",
      "tensor(-3.2732e+33) tensor(2.0452e+35)\n",
      "tensor(5.2790e+34) tensor(1.2320e+36)\n",
      "tensor(9.1186e+35) tensor(8.0654e+36)\n",
      "tensor(-inf) tensor(inf)\n",
      "Numerical instability at layer 43\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(bs, m)  # input image\n",
    "\n",
    "for i in range(100): \n",
    "    w = torch.randn(m, nh) if i == 0 else torch.randn(nh, nh)\n",
    "    \n",
    "    a = lin(a, w)\n",
    "    print(a.mean(), a.std())\n",
    "    if torch.isinf(a.std()) or torch.isnan(a.std()):\n",
    "        print(f\"Numerical instability at layer {i}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e3e253",
   "metadata": {},
   "source": [
    "The bias term helps to keep the variance more numerically stable, thus allowing us to train deeper networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c776c247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2948) tensor(25.2224)\n",
      "tensor(11.3351) tensor(157.6096)\n",
      "tensor(39.7886) tensor(888.9370)\n",
      "tensor(305.9420) tensor(5561.0532)\n",
      "tensor(-4947.6919) tensor(42374.2031)\n",
      "tensor(-45642.4648) tensor(231599.9531)\n",
      "tensor(-269654.5938) tensor(1517741.1250)\n",
      "tensor(-1216053.5000) tensor(10389182.)\n",
      "tensor(-696933.7500) tensor(77055200.)\n",
      "tensor(-41839628.) tensor(5.1609e+08)\n",
      "tensor(2.3685e+08) tensor(3.5630e+09)\n",
      "tensor(5.2460e+09) tensor(2.5518e+10)\n",
      "tensor(2.0887e+10) tensor(1.6205e+11)\n",
      "tensor(1.2260e+11) tensor(1.0795e+12)\n",
      "tensor(9.1355e+11) tensor(5.9297e+12)\n",
      "tensor(-6.1938e+11) tensor(4.4245e+13)\n",
      "tensor(7.6832e+12) tensor(3.0600e+14)\n",
      "tensor(2.9639e+14) tensor(2.1948e+15)\n",
      "tensor(-9.9300e+14) tensor(1.7176e+16)\n",
      "tensor(-1.4316e+16) tensor(1.1445e+17)\n",
      "tensor(1.2421e+16) tensor(8.1405e+17)\n",
      "tensor(9.5092e+17) tensor(5.7035e+18)\n",
      "tensor(-3.8658e+16) tensor(3.5691e+19)\n",
      "tensor(3.0521e+19) tensor(2.1759e+20)\n",
      "tensor(5.3957e+20) tensor(1.4464e+21)\n",
      "tensor(1.4418e+21) tensor(1.1056e+22)\n",
      "tensor(6.8730e+21) tensor(7.3023e+22)\n",
      "tensor(-1.7606e+23) tensor(5.6427e+23)\n",
      "tensor(-1.1474e+20) tensor(3.9111e+24)\n",
      "tensor(4.2229e+24) tensor(2.5171e+25)\n",
      "tensor(3.3144e+25) tensor(2.2936e+26)\n",
      "tensor(-2.2249e+25) tensor(1.5219e+27)\n",
      "tensor(-1.0832e+27) tensor(1.1085e+28)\n",
      "tensor(-9.8086e+27) tensor(7.0962e+28)\n",
      "tensor(-3.3058e+28) tensor(4.1083e+29)\n",
      "tensor(2.6611e+28) tensor(2.7987e+30)\n",
      "tensor(1.1224e+29) tensor(1.8023e+31)\n",
      "tensor(-8.8461e+30) tensor(1.3421e+32)\n",
      "tensor(8.6622e+31) tensor(9.1858e+32)\n",
      "tensor(-1.3703e+33) tensor(5.9291e+33)\n",
      "tensor(-5.8986e+33) tensor(4.2360e+34)\n",
      "tensor(-4.3573e+34) tensor(2.9399e+35)\n",
      "tensor(1.2293e+34) tensor(2.4429e+36)\n",
      "tensor(9.5976e+35) tensor(1.7863e+37)\n",
      "tensor(nan) tensor(nan)\n",
      "Numerical instability at layer 44\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(bs, m)  # input image\n",
    "\n",
    "for i in range(100): \n",
    "    w = torch.randn(m, nh) if i == 0 else torch.randn(nh, nh)\n",
    "    b = torch.randn(nh)\n",
    "\n",
    "    a = lin(a, w, b)\n",
    "    print(a.mean(), a.std())\n",
    "    if torch.isinf(a.std()) or torch.isnan(a.std()):\n",
    "        print(f\"Numerical instability at layer {i}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546aeb15",
   "metadata": {},
   "source": [
    "Note, however, how the mean and std of the feature maps generate by every layer are still very large. This network, despite being deeper, will not be able to learn much."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3f112c",
   "metadata": {},
   "source": [
    "### Is a good init sufficient to fix the issue?\n",
    "\n",
    "Improving the init further helps delaying the activation explosion issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d7e3cea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0711) tensor(1.4957)\n",
      "tensor(-0.0511) tensor(1.0095)\n",
      "tensor(-0.4422) tensor(1.1059)\n",
      "tensor(0.1277) tensor(1.0596)\n",
      "tensor(-0.3985) tensor(1.3124)\n",
      "tensor(0.1857) tensor(1.0094)\n",
      "tensor(-0.0760) tensor(0.9465)\n",
      "tensor(0.0490) tensor(1.1492)\n",
      "tensor(0.1703) tensor(0.9531)\n",
      "tensor(0.0941) tensor(0.9850)\n",
      "tensor(0.2780) tensor(1.1059)\n",
      "tensor(0.3568) tensor(1.1376)\n",
      "tensor(-0.1717) tensor(1.1406)\n",
      "tensor(0.1412) tensor(1.0808)\n",
      "tensor(-0.0173) tensor(0.9722)\n",
      "tensor(-0.0411) tensor(1.0436)\n",
      "tensor(-0.1327) tensor(1.0183)\n",
      "tensor(-0.0854) tensor(0.9669)\n",
      "tensor(0.0919) tensor(1.0189)\n",
      "tensor(0.0479) tensor(1.0539)\n",
      "tensor(0.0948) tensor(0.9043)\n",
      "tensor(-0.0322) tensor(0.8762)\n",
      "tensor(-0.0547) tensor(1.0981)\n",
      "tensor(0.0137) tensor(1.1735)\n",
      "tensor(0.0523) tensor(0.9133)\n",
      "tensor(-0.0798) tensor(0.9836)\n",
      "tensor(-0.0092) tensor(1.0789)\n",
      "tensor(0.0777) tensor(0.9722)\n",
      "tensor(-0.2081) tensor(1.0408)\n",
      "tensor(0.2621) tensor(1.0460)\n",
      "tensor(-0.0367) tensor(1.1459)\n",
      "tensor(0.1246) tensor(0.8488)\n",
      "tensor(-0.0796) tensor(0.9960)\n",
      "tensor(0.1274) tensor(1.0221)\n",
      "tensor(-0.2454) tensor(1.1485)\n",
      "tensor(0.0020) tensor(1.0171)\n",
      "tensor(0.2115) tensor(1.1676)\n",
      "tensor(0.0733) tensor(1.1719)\n",
      "tensor(-0.0630) tensor(1.2446)\n",
      "tensor(0.0018) tensor(1.3174)\n",
      "tensor(0.0123) tensor(0.9973)\n",
      "tensor(-0.0502) tensor(1.1679)\n",
      "tensor(0.2498) tensor(1.0307)\n",
      "tensor(0.1810) tensor(1.0315)\n",
      "tensor(0.0178) tensor(1.1599)\n",
      "tensor(0.0061) tensor(1.0270)\n",
      "tensor(-0.0534) tensor(0.9572)\n",
      "tensor(-0.0092) tensor(1.0511)\n",
      "tensor(-0.0992) tensor(1.0028)\n",
      "tensor(-0.0224) tensor(1.0016)\n",
      "tensor(0.2193) tensor(1.1231)\n",
      "tensor(0.0484) tensor(1.2026)\n",
      "tensor(0.0110) tensor(1.1950)\n",
      "tensor(0.0024) tensor(0.9755)\n",
      "tensor(-0.2667) tensor(0.9747)\n",
      "tensor(0.0169) tensor(1.0446)\n",
      "tensor(-0.2692) tensor(1.0635)\n",
      "tensor(-0.1313) tensor(1.3002)\n",
      "tensor(-0.2045) tensor(1.0886)\n",
      "tensor(0.0933) tensor(1.0473)\n",
      "tensor(-0.0898) tensor(1.0275)\n",
      "tensor(-0.0645) tensor(0.9002)\n",
      "tensor(0.2124) tensor(0.9693)\n",
      "tensor(0.0595) tensor(0.9011)\n",
      "tensor(0.0817) tensor(1.1575)\n",
      "tensor(-0.2615) tensor(1.1784)\n",
      "tensor(0.1075) tensor(1.1041)\n",
      "tensor(-0.0183) tensor(1.1677)\n",
      "tensor(-0.0391) tensor(1.0687)\n",
      "tensor(0.1564) tensor(0.8248)\n",
      "tensor(0.1282) tensor(0.9917)\n",
      "tensor(-0.0072) tensor(0.9654)\n",
      "tensor(-0.0261) tensor(0.9956)\n",
      "tensor(0.1814) tensor(1.0355)\n",
      "tensor(0.0244) tensor(1.2018)\n",
      "tensor(-0.0592) tensor(1.0770)\n",
      "tensor(0.0955) tensor(0.9344)\n",
      "tensor(-0.0676) tensor(1.0841)\n",
      "tensor(0.0899) tensor(1.0456)\n",
      "tensor(0.0034) tensor(0.9584)\n",
      "tensor(-0.2662) tensor(0.8847)\n",
      "tensor(-0.2864) tensor(1.2439)\n",
      "tensor(-0.0099) tensor(1.0614)\n",
      "tensor(0.0386) tensor(0.9765)\n",
      "tensor(0.1518) tensor(0.9912)\n",
      "tensor(-0.2748) tensor(0.8911)\n",
      "tensor(0.1064) tensor(1.1966)\n",
      "tensor(-0.0500) tensor(0.9364)\n",
      "tensor(-0.2474) tensor(0.9570)\n",
      "tensor(-0.0604) tensor(1.0037)\n",
      "tensor(-0.1647) tensor(1.2747)\n",
      "tensor(-0.0436) tensor(0.9338)\n",
      "tensor(-0.0151) tensor(1.0645)\n",
      "tensor(0.0287) tensor(1.1094)\n",
      "tensor(0.2024) tensor(0.9726)\n",
      "tensor(0.2496) tensor(0.9783)\n",
      "tensor(0.2043) tensor(0.9098)\n",
      "tensor(-0.0575) tensor(0.9485)\n",
      "tensor(-0.0385) tensor(1.0315)\n",
      "tensor(0.0062) tensor(1.0103)\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(bs, m)  # input image\n",
    "\n",
    "for i in range(100): \n",
    "    w = torch.randn(m, nh) / math.sqrt(m) if i == 0 else torch.randn(nh, nh) / math.sqrt(m)  # xavier init\n",
    "    b = torch.randn(nh)\n",
    "\n",
    "    a = lin(a, w, b)\n",
    "    print(a.mean(), a.std())\n",
    "    if torch.isinf(a.std()) or torch.isnan(a.std()):\n",
    "        print(f\"Numerical instability at layer {i}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca7affa",
   "metadata": {},
   "source": [
    "Let's do an ablation study and try Xavier init without using the bias term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c17be093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1339) tensor(0.9245)\n",
      "tensor(0.0319) tensor(0.2444)\n",
      "tensor(-0.0045) tensor(0.0622)\n",
      "tensor(0.0019) tensor(0.0140)\n",
      "tensor(-0.0004) tensor(0.0032)\n",
      "tensor(-4.7454e-05) tensor(0.0008)\n",
      "tensor(2.6425e-06) tensor(0.0002)\n",
      "tensor(1.3865e-06) tensor(5.3755e-05)\n",
      "tensor(3.1186e-06) tensor(1.4076e-05)\n",
      "tensor(-3.4377e-08) tensor(3.8901e-06)\n",
      "tensor(-9.4254e-08) tensor(9.7954e-07)\n",
      "tensor(1.7289e-08) tensor(2.7845e-07)\n",
      "tensor(-4.1952e-09) tensor(6.8295e-08)\n",
      "tensor(-8.0264e-10) tensor(1.6526e-08)\n",
      "tensor(2.3847e-10) tensor(4.0860e-09)\n",
      "tensor(-1.3845e-10) tensor(9.3302e-10)\n",
      "tensor(1.5291e-11) tensor(2.4523e-10)\n",
      "tensor(-7.7738e-12) tensor(6.5599e-11)\n",
      "tensor(3.3116e-12) tensor(1.6463e-11)\n",
      "tensor(7.6094e-13) tensor(3.7808e-12)\n",
      "tensor(-2.5715e-14) tensor(8.1276e-13)\n",
      "tensor(-4.0869e-14) tensor(2.1212e-13)\n",
      "tensor(-5.1578e-16) tensor(6.2611e-14)\n",
      "tensor(4.0379e-15) tensor(1.6626e-14)\n",
      "tensor(9.6956e-16) tensor(3.9063e-15)\n",
      "tensor(-1.5877e-16) tensor(9.1845e-16)\n",
      "tensor(1.3143e-17) tensor(2.4905e-16)\n",
      "tensor(-6.3666e-19) tensor(6.2962e-17)\n",
      "tensor(-1.9710e-18) tensor(1.4042e-17)\n",
      "tensor(1.2852e-18) tensor(3.3158e-18)\n",
      "tensor(1.3196e-19) tensor(8.8478e-19)\n",
      "tensor(3.3317e-20) tensor(2.4391e-19)\n",
      "tensor(6.1132e-22) tensor(7.2257e-20)\n",
      "tensor(5.4018e-21) tensor(1.5411e-20)\n",
      "tensor(-5.1972e-22) tensor(3.6235e-21)\n",
      "tensor(-1.1360e-22) tensor(8.4437e-22)\n",
      "tensor(3.8559e-23) tensor(2.1745e-22)\n",
      "tensor(-1.1910e-24) tensor(6.4498e-23)\n",
      "tensor(3.5007e-25) tensor(1.7091e-23)\n",
      "tensor(1.2196e-25) tensor(3.7394e-24)\n",
      "tensor(2.6613e-26) tensor(9.6894e-25)\n",
      "tensor(-2.2379e-26) tensor(2.5767e-25)\n",
      "tensor(-5.3529e-27) tensor(6.3689e-26)\n",
      "tensor(5.5844e-28) tensor(1.7898e-26)\n",
      "tensor(-4.3849e-28) tensor(4.6440e-27)\n",
      "tensor(-3.1808e-28) tensor(1.1275e-27)\n",
      "tensor(-4.1237e-29) tensor(2.6753e-28)\n",
      "tensor(1.6621e-30) tensor(7.0475e-29)\n",
      "tensor(-2.6815e-30) tensor(1.6310e-29)\n",
      "tensor(-1.5034e-31) tensor(3.5328e-30)\n",
      "tensor(2.1405e-31) tensor(7.1129e-31)\n",
      "tensor(5.9841e-33) tensor(1.6354e-31)\n",
      "tensor(-6.4216e-34) tensor(4.1573e-32)\n",
      "tensor(1.0377e-33) tensor(9.6481e-33)\n",
      "tensor(-4.4351e-35) tensor(2.2877e-33)\n",
      "tensor(4.2736e-35) tensor(5.6905e-34)\n",
      "tensor(-9.3686e-37) tensor(1.6604e-34)\n",
      "tensor(-5.0964e-36) tensor(4.5176e-35)\n",
      "tensor(-9.5190e-37) tensor(9.8054e-36)\n",
      "tensor(-3.2869e-37) tensor(2.7639e-36)\n",
      "tensor(-3.0442e-39) tensor(5.6518e-37)\n",
      "tensor(-1.9671e-39) tensor(1.4604e-37)\n",
      "tensor(6.7542e-39) tensor(3.6831e-38)\n",
      "tensor(-2.5948e-39) tensor(9.4979e-39)\n",
      "tensor(-5.3233e-40) tensor(2.0751e-39)\n",
      "tensor(-1.8906e-41) tensor(4.9011e-40)\n",
      "tensor(1.2337e-41) tensor(1.2087e-40)\n",
      "tensor(4.9466e-42) tensor(2.5773e-41)\n",
      "tensor(-7.9454e-43) tensor(5.7481e-42)\n",
      "tensor(-2.7045e-43) tensor(1.5807e-42)\n",
      "tensor(-7.0065e-44) tensor(4.0498e-43)\n",
      "tensor(-9.8091e-45) tensor(1.1771e-43)\n",
      "tensor(-0.) tensor(3.0829e-44)\n",
      "tensor(-0.) tensor(7.0065e-45)\n",
      "tensor(-0.) tensor(1.4013e-45)\n",
      "tensor(0.) tensor(0.)\n",
      "tensor(0.) tensor(0.)\n",
      "tensor(0.) tensor(0.)\n",
      "tensor(0.) tensor(0.)\n",
      "tensor(0.) tensor(0.)\n",
      "tensor(0.) tensor(0.)\n",
      "tensor(0.) tensor(0.)\n",
      "tensor(0.) tensor(0.)\n",
      "tensor(0.) tensor(0.)\n",
      "tensor(0.) tensor(0.)\n",
      "tensor(0.) tensor(0.)\n",
      "tensor(0.) tensor(0.)\n",
      "tensor(0.) tensor(0.)\n",
      "tensor(0.) tensor(0.)\n",
      "tensor(0.) tensor(0.)\n",
      "tensor(0.) tensor(0.)\n",
      "tensor(0.) tensor(0.)\n",
      "tensor(0.) tensor(0.)\n",
      "tensor(0.) tensor(0.)\n",
      "tensor(0.) tensor(0.)\n",
      "tensor(0.) tensor(0.)\n",
      "tensor(0.) tensor(0.)\n",
      "tensor(0.) tensor(0.)\n",
      "tensor(0.) tensor(0.)\n",
      "tensor(0.) tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(bs, m)  # input image\n",
    "\n",
    "for i in range(100): \n",
    "    w = torch.randn(m, nh) / math.sqrt(m) if i == 0 else torch.randn(nh, nh) / math.sqrt(m)\n",
    "\n",
    "    a = lin(a, w)\n",
    "    print(a.mean(), a.std())\n",
    "    if torch.isinf(a.std()) or torch.isnan(a.std()):\n",
    "        print(f\"Numerical instability at layer {i}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5bf5b1",
   "metadata": {},
   "source": [
    "Removing the bias term shows that just a good init is not enough. The purpose of the bias term is to improve numerical stability in the forward pass. Without a bias term, it is harder to train deep architectures.\n",
    "\n",
    "In each layer of the forward pass, we are multiplying the previous layer's output activation by a set of weights close to zero. Repeating this step multiple times will lead to a set of output activation with a std so small that it clamps to `nan`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebb382c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.01, 0.0001, 1.0000000000000002e-06)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 * 0.01, 1 * 0.01 * 0.01, 1 * 0.01 * 0.01 * 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83020c88",
   "metadata": {},
   "source": [
    "### TODO\n",
    "\n",
    "- [ ] Does Xavier init make any assumption about the bias term?\n",
    "- [ ] Plot activations for each layer\n",
    "- [ ] Backward pass\n",
    "- [ ] Conv layer\n",
    "- [ ] BatchNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67626706",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
