{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a6286dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f445c4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c16c622",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ef3fb50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: /workspace/data/\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = MNIST('/workspace/data/', download=True, transform=transforms.ToTensor())\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "293ed8bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef415690",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = 50_000\n",
    "n_valid = dataset.data.shape[0] - n_train\n",
    "x_train, y_train = dataset.data[:n_train, :, :].view(n_train, -1) / 255, dataset.targets[:n_train]\n",
    "x_valid, y_valid = dataset.data[n_train:, :, :].view(n_valid, -1) / 255, dataset.targets[n_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8010126e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1310), tensor(0.3085))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mean, train_std = x_train.mean(), x_train.std()\n",
    "train_mean, train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b43f75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x, m, s):\n",
    "    return (x - m) / s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1658f757",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = normalize(x_train, train_mean, train_std)\n",
    "# NOTE: use training, not validation mean and std for validation set\n",
    "x_valid = normalize(x_valid, train_mean, train_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c87f2fe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(2.1126e-08), tensor(1.))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.mean(), x_train.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cea57711",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_near_zero(x, tol=1e-3):\n",
    "    assert x.abs() < tol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74f3ec5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_near_zero(x_train.mean())\n",
    "test_near_zero(x_train.std() - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39c959a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 784, tensor(10))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n, m = x_train.shape\n",
    "c = y_train.max() + 1\n",
    "n, m, c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412b9a6b",
   "metadata": {},
   "source": [
    "## Basic architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2aca4501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num hidden units\n",
    "nh = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa6d1c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random init (0, 1)\n",
    "w1 = torch.randn(m, nh)\n",
    "b1 = torch.zeros(nh)  # it gets broadcasted to (n, nh)\n",
    "w2 = torch.randn(nh, 1)\n",
    "b2 = torch.zeros(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1e4c655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.0059), tensor(0.9924))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this should roughly be (0, 1)\n",
    "x_valid.mean(), x_valid.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13c0d2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin(x, w, b):\n",
    "    return (x @ w) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "215cc4a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(5.3403), tensor(27.3566))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = lin(x_valid, w1, b1)\n",
    "t.mean(), t.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ea5bb6",
   "metadata": {},
   "source": [
    "This is a pretty terrible result, as it will lead to exploding gradients after just a few layers. Let's use Xavier init to make mean and std of the output activation closer to (0, 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55823e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simplified xavier init\n",
    "w1 = torch.randn(m, nh) / math.sqrt(m)\n",
    "b1 = torch.zeros(nh)  # it gets broadcasted to (n, nh)\n",
    "w2 = torch.randn(nh, 1) / math.sqrt(nh)\n",
    "b2 = torch.zeros(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "254cb380",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_near_zero(w1.mean())\n",
    "test_near_zero(w1.std() - 1 / math.sqrt(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "81ba77fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0253), tensor(1.0077))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ... so should this, since we used kaiming he init, which is designed to do this\n",
    "t = lin(x_valid, w1, b1)\n",
    "t.mean(), t.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0f9d92",
   "metadata": {},
   "source": [
    "This is promising, however, it doesn't take into account the non-linearity activation. Modern networks use ReLu, Swish, Mish, etc. Xavier init doesn't work well with such non-linearities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "71dcf479",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x: torch.Tensor):\n",
    "    return x.clamp_min(0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ddacfd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = relu(lin(x_valid, w1, b1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa5d735b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.4120), tensor(0.5892))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.mean(), t.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ae7705",
   "metadata": {},
   "source": [
    "As you can notice, the output is not centered at 0 and the std is far from 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "81fb3abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kaiming he init for relu\n",
    "# Delving Deep into Rectifiers: Surpassing Human-Level Performance on \n",
    "#   ImageNet Classification (https://arxiv.org/abs/1502.01852)\n",
    "w1 = torch.randn(m, nh) * math.sqrt(2/m)\n",
    "b1 = torch.zeros(nh)  # it gets broadcasted to (n, nh)\n",
    "w2 = torch.randn(nh, 1) * math.sqrt(2/nh)\n",
    "b2 = torch.zeros(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8bdf6d37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0004), tensor(0.0506))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1.mean(), w1.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7a27f7a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.6173), tensor(0.8642))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = relu(lin(x_valid, w1, b1))\n",
    "t.mean(), t.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f6ec9f",
   "metadata": {},
   "source": [
    "This gives us a much better standard deviation â€• closer to 1. The mean is not close to zero, but that is intentional. The ReLu activation removed every value below 0, thus the mean cannot be zero. Something closer to 0.5 is now expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "61b6c53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "991ce7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = torch.randn(m, nh)\n",
    "init.kaiming_normal_(w1, mode='fan_out')\n",
    "t = relu(lin(x_valid, w1, b1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ddd38e97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(7.3173e-05), tensor(0.0506))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1.mean(), w1.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aded121d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.5555), tensor(0.7981))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.mean(), t.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bc9604",
   "metadata": {},
   "source": [
    "What if we change the definition of ReLu to also subtract 0.5, to bring the mean back to 0..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "be4b5a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what if...\n",
    "def relu(x):\n",
    "    return x.clamp_min(0.) - 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d789751b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0908), tensor(0.7981))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# kaiming-he init for relu\n",
    "w1 = torch.randn(m, nh) * math.sqrt(2./m)\n",
    "t1 = relu(lin(x_valid, w1, b1))\n",
    "t1.mean(), t.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fe8ab8",
   "metadata": {},
   "source": [
    "The mean is now closer to 0 and the standard deviation is more stable and closer to 0.8 â€• not perfect, but it's better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cb5360",
   "metadata": {},
   "source": [
    "## Forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "59875f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(xb):\n",
    "    l1 = lin(xb, w1, b1)\n",
    "    l2 = relu(l1)\n",
    "    l3 = lin(l2, w2, b2)\n",
    "    return l3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a5534e0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2013],\n",
       "        [-1.1672],\n",
       "        [-1.0462],\n",
       "        ...,\n",
       "        [ 0.2116],\n",
       "        [-0.4987],\n",
       "        [-0.8638]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model(x_valid)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0f15541f",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert y_pred.shape == torch.Size([x_valid.shape[0], 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fc8fe3",
   "metadata": {},
   "source": [
    "## Loss function: MSE\n",
    "\n",
    "Of course, MSE is not a suitable loss function for multi-class classification; we will use a better loss function soon. For now, let's use MSE to keep things simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ae5d3f9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 1])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c7679234",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(output, targ): return (output.squeeze(-1) - targ).pow(2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4c1c9c31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(31.0382)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse(y_pred, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d94ac9",
   "metadata": {},
   "source": [
    "## Gradients and backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dc45b509",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_grad(inp, targ):\n",
    "    # grad of loss function w.r.t. output of previous layer\n",
    "    inp.g = 2. * (inp.squeeze() - targ).unsqueeze(-1) / inp.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a18f402f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_grad(inp, out):\n",
    "    # grad of ReLu w.r.t. input activations\n",
    "    inp.g = (inp>0).float() * out.g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4d342ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin_grad(inp, out, w, b):\n",
    "    # grad of matmul w.r.t. input\n",
    "    inp.g = out.g @ w.t()\n",
    "    w.g = (inp.unsqueeze(-1) * out.g.unsqueeze(1)).sum(0)\n",
    "    b.g = out.g.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c475403d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_and_backward(inp, targ):\n",
    "    # forward pass\n",
    "    l1 = inp @ w1 + b1\n",
    "    l2 = relu(l1)\n",
    "    out = l2 @ w2 + b2\n",
    "    # we don't actually need the loss in the backward pass!\n",
    "    loss = mse(out, targ)\n",
    "    \n",
    "    # backward pass\n",
    "    mse_grad(out, targ)\n",
    "    lin_grad(l2, out, w2, b2)\n",
    "    relu_grad(l1, l2)\n",
    "    lin_grad(inp, l1, w1, b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e730c360",
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_and_backward(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5cf8f0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save for testing later\n",
    "w1g = w1.g.clone()\n",
    "w2g = w2.g.clone()\n",
    "b1g = b1.g.clone()\n",
    "b2g = b2.g.clone()\n",
    "ig  = x_train.g.clone()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d211cd93",
   "metadata": {},
   "source": [
    "Let's check the results against PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "97cbc8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "xt2 = x_train.clone().requires_grad_(True)\n",
    "w12 = w1.clone().requires_grad_(True)\n",
    "w22 = w2.clone().requires_grad_(True)\n",
    "b12 = b1.clone().requires_grad_(True)\n",
    "b22 = b2.clone().requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6c93cc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(inp, targ):\n",
    "    # forward pass\n",
    "    l1 = inp @ w12 + b12\n",
    "    l2 = relu(l1)\n",
    "    out = l2 @ w22 + b22\n",
    "    # we don't actually need the loss in backward!\n",
    "    return mse(out, targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6047d9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = forward(xt2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6675aa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cfe0539c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_near(a: torch.tensor, b:torch.tensor):\n",
    "    return torch.allclose(a, b, rtol=1e-3, atol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d04ef066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_near(w22.grad, w2g)\n",
    "test_near(b22.grad, b2g)\n",
    "test_near(w12.grad, w1g)\n",
    "test_near(b12.grad, b1g)\n",
    "test_near(xt2.grad, ig )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f067ec",
   "metadata": {},
   "source": [
    "## Refactor model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c7564c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relu():\n",
    "    def __call__(self, inp):\n",
    "        self.inp = inp\n",
    "        self.out = inp.clamp_min(0.) - 0.5\n",
    "        return self.out\n",
    "    \n",
    "    def backward(self):\n",
    "        self.inp.g = (self.inp > 0).float() * self.out.g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bfc01d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lin():\n",
    "    def __init__(self, w, b):\n",
    "        self.w = w\n",
    "        self.b = b\n",
    "        \n",
    "    def __call__(self, inp):\n",
    "        self.inp = inp\n",
    "        self.out = inp @ self.w + self.b\n",
    "        return self.out\n",
    "    \n",
    "    def backward(self):\n",
    "        self.inp.g = self.out.g @ self.w.t()\n",
    "        # creating a giant outer product, just to sum it, is inefficient!\n",
    "        self.w.g = (self.inp.unsqueeze(-1) * self.out.g.unsqueeze(1)).sum(0)\n",
    "        self.b.g = self.out.g.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d7465d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mse:\n",
    "    def __call__(self, inp, targ):\n",
    "        self.inp = inp\n",
    "        self.targ = targ\n",
    "        self.out = (inp.squeeze(-1) - targ).pow(2).mean()\n",
    "        return self.out\n",
    "    \n",
    "    def backward(self):\n",
    "        self.inp.g = 2. * (self.inp.squeeze() - self.targ).unsqueeze(-1) / self.inp.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "db73792f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__(self, w1, b1, w2, b2):\n",
    "        self.layers = [Lin(w1, b1), Relu(), Lin(w2, b2)]\n",
    "        self.loss = Mse()\n",
    "        \n",
    "    def __call__(self, x, targ):\n",
    "        for l in self.layers:\n",
    "            x = l(x)\n",
    "        return self.loss(x, targ)\n",
    "    \n",
    "    def backward(self):\n",
    "        self.loss.backward()\n",
    "        for l in reversed(self.layers):\n",
    "            l.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c0fbd74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1.g, b1.g, w2.g, b2.g = [None] * 4\n",
    "model = Model(w1, b1, w2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c31db4b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 94.6 ms, sys: 0 ns, total: 94.6 ms\n",
      "Wall time: 17.2 ms\n"
     ]
    }
   ],
   "source": [
    "%time loss = model(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0124602c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 s, sys: 2.34 s, total: 7.34 s\n",
      "Wall time: 1.46 s\n"
     ]
    }
   ],
   "source": [
    "%time model.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "41d419bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_near(w2g, w2.g)\n",
    "test_near(b2g, b2.g)\n",
    "test_near(w1g, w1.g)\n",
    "test_near(b1g, b1.g)\n",
    "test_near(ig, x_train.g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4b857d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Module():\n",
    "    def __call__(self, *args):\n",
    "        self.args = args\n",
    "        self.out = self.forward(*args)\n",
    "        return self.out\n",
    "    \n",
    "    def forward(self):\n",
    "        raise NotImplemented()\n",
    "    \n",
    "    def backward(self):\n",
    "        self.bwd(self.out, *self.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a9189388",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relu(Module):\n",
    "    def forward(self, inp):\n",
    "        return inp.clamp_min(0.) - 0.5\n",
    "    \n",
    "    def bwd(self, out, inp):\n",
    "        inp.g = (inp > 0).float() * out.g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "38fc6dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lin(Module):\n",
    "    def __init__(self, w, b):\n",
    "        self.w = w\n",
    "        self.b = b\n",
    "        \n",
    "    def forward(self, inp):\n",
    "        return inp @ self.w + self.b\n",
    "        \n",
    "    def bwd(self, out, inp):\n",
    "        inp.g = out.g @ self.w.t()\n",
    "        # creating a giant outer product, just to sum it, is inefficient!\n",
    "        self.w.g = torch.einsum('bi,bj->ij', inp, out.g)\n",
    "        self.b.g = out.g.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3223f339",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mse(Module):\n",
    "    def forward(self, inp, targ):\n",
    "        return (inp.squeeze(-1) - targ).pow(2).mean()\n",
    "        \n",
    "    def bwd(self, out, inp, targ):\n",
    "        inp.g = 2. * (inp.squeeze() - targ).unsqueeze(-1) / inp.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "13934be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__(self):\n",
    "        self.layers = [Lin(w1, b1), Relu(), Lin(w2, b2)]\n",
    "        self.loss = Mse()\n",
    "        \n",
    "    def __call__(self, x, targ):\n",
    "        for l in self.layers:\n",
    "            x = l(x)\n",
    "        return self.loss(x, targ)\n",
    "    \n",
    "    def backward(self):\n",
    "        self.loss.backward()\n",
    "        for l in reversed(self.layers):\n",
    "            l.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "054f3838",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1.g, b1.g, w2.g, b2.g = [None] * 4\n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "980ad90e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 109 ms, sys: 0 ns, total: 109 ms\n",
      "Wall time: 19.4 ms\n"
     ]
    }
   ],
   "source": [
    "%time loss = model(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6e122bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 223 ms, sys: 100 ms, total: 323 ms\n",
      "Wall time: 56.3 ms\n"
     ]
    }
   ],
   "source": [
    "%time model.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4fa1363c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_near(w2g, w2.g)\n",
    "test_near(b2g, b2.g)\n",
    "test_near(w1g, w1.g)\n",
    "test_near(b1g, b1.g)\n",
    "test_near(ig, x_train.g)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7cd637",
   "metadata": {},
   "source": [
    "## Without Einsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b281484a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lin(Module):\n",
    "    def __init__(self, w, b):\n",
    "        self.w = w\n",
    "        self.b = b\n",
    "        \n",
    "    def forward(self, inp):\n",
    "        return inp @ self.w + self.b\n",
    "        \n",
    "    def bwd(self, out, inp):\n",
    "        inp.g = out.g @ self.w.t()\n",
    "        # creating a giant outer product, just to sum it, is inefficient!\n",
    "        self.w.g = inp.t() @ out.g\n",
    "        self.b.g = out.g.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fe5189ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1.g, b1.g, w2.g, b2.g = [None] * 4\n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "363a5f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 82.1 ms, sys: 0 ns, total: 82.1 ms\n",
      "Wall time: 16.6 ms\n"
     ]
    }
   ],
   "source": [
    "%time loss = model(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6ae054f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 191 ms, sys: 71.7 ms, total: 263 ms\n",
      "Wall time: 46.2 ms\n"
     ]
    }
   ],
   "source": [
    "%time model.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a12ff00a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_near(w2g, w2.g)\n",
    "test_near(b2g, b2.g)\n",
    "test_near(w1g, w1.g)\n",
    "test_near(b1g, b1.g)\n",
    "test_near(ig, x_train.g)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0320d138",
   "metadata": {},
   "source": [
    "## nn.Linear and nn.Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c04364ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "aab5f1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        super().__init__()\n",
    "        self.layers = [\n",
    "            nn.Linear(n_in, nh),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(nh, n_out)]\n",
    "        self.loss = mse\n",
    "        \n",
    "    def __call__(self, x, targ):\n",
    "        for l in self.layers:\n",
    "            x = l(x)\n",
    "        return self.loss(x.squeeze(), targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5b92b159",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(m, nh, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1790e66a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 74.4 ms, sys: 976 Âµs, total: 75.4 ms\n",
      "Wall time: 15.6 ms\n"
     ]
    }
   ],
   "source": [
    "%time loss = model(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "469a5227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 71.6 ms, sys: 0 ns, total: 71.6 ms\n",
      "Wall time: 14.9 ms\n"
     ]
    }
   ],
   "source": [
    "%time loss.backward()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
