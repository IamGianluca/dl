{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b57e153",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f323f9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.nn import init\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95ef49b",
   "metadata": {},
   "source": [
    "### Where does the default parameter `a=math.sqrt(5)` for `kaiming_uniform_` come from?\n",
    "\n",
    "The default init strategy for Conv2d layers in PyTorch is Kaiming uniform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e3f851c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m <no docstring>\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "    \u001b[0;32mdef\u001b[0m \u001b[0mreset_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# Setting a=sqrt(5) in kaiming_uniform is the same as initializing with\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# uniform(-1/sqrt(k), 1/sqrt(k)), where k = weight.size(1) * prod(*kernel_size)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# For more details see: https://github.com/pytorch/pytorch/issues/15314#issuecomment-477448573\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0minit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkaiming_uniform_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mfan_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_calculate_fan_in_and_fan_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mfan_in\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfan_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0minit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mbound\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\n",
       "\u001b[0;31mType:\u001b[0m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nn.modules.conv._ConvNd.reset_parameters??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9de09853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkaiming_uniform_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0ma\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'fan_in'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnonlinearity\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'leaky_relu'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "\u001b[0;32mdef\u001b[0m \u001b[0mkaiming_uniform_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'fan_in'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnonlinearity\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'leaky_relu'\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34mr\"\"\"Fills the input `Tensor` with values according to the method\u001b[0m\n",
       "\u001b[0;34m    described in `Delving deep into rectifiers: Surpassing human-level\u001b[0m\n",
       "\u001b[0;34m    performance on ImageNet classification` - He, K. et al. (2015), using a\u001b[0m\n",
       "\u001b[0;34m    uniform distribution. The resulting tensor will have values sampled from\u001b[0m\n",
       "\u001b[0;34m    :math:`\\mathcal{U}(-\\text{bound}, \\text{bound})` where\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    .. math::\u001b[0m\n",
       "\u001b[0;34m        \\text{bound} = \\text{gain} \\times \\sqrt{\\frac{3}{\\text{fan\\_mode}}}\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Also known as He initialization.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Args:\u001b[0m\n",
       "\u001b[0;34m        tensor: an n-dimensional `torch.Tensor`\u001b[0m\n",
       "\u001b[0;34m        a: the negative slope of the rectifier used after this layer (only\u001b[0m\n",
       "\u001b[0;34m            used with ``'leaky_relu'``)\u001b[0m\n",
       "\u001b[0;34m        mode: either ``'fan_in'`` (default) or ``'fan_out'``. Choosing ``'fan_in'``\u001b[0m\n",
       "\u001b[0;34m            preserves the magnitude of the variance of the weights in the\u001b[0m\n",
       "\u001b[0;34m            forward pass. Choosing ``'fan_out'`` preserves the magnitudes in the\u001b[0m\n",
       "\u001b[0;34m            backwards pass.\u001b[0m\n",
       "\u001b[0;34m        nonlinearity: the non-linear function (`nn.functional` name),\u001b[0m\n",
       "\u001b[0;34m            recommended to use only with ``'relu'`` or ``'leaky_relu'`` (default).\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Examples:\u001b[0m\n",
       "\u001b[0;34m        >>> w = torch.empty(3, 5)\u001b[0m\n",
       "\u001b[0;34m        >>> nn.init.kaiming_uniform_(w, mode='fan_in', nonlinearity='relu')\u001b[0m\n",
       "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mkaiming_uniform_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mtensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mnonlinearity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnonlinearity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Initializing zero-element tensors is a no-op\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_calculate_correct_fan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mgain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_gain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnonlinearity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgain\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mstd\u001b[0m  \u001b[0;31m# Calculate uniform bounds from standard deviation\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mbound\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      /usr/local/lib/python3.10/dist-packages/torch/nn/init.py\n",
       "\u001b[0;31mType:\u001b[0m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nn.init.kaiming_uniform_??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1939fecc",
   "metadata": {},
   "source": [
    "Interestingly, the default value assumed for the negative slope of the rectifier unit seems arbitrary. Where does `a=math.sqrt(5)` come from? Does it work well in practice? Let's find out..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf77b460",
   "metadata": {},
   "source": [
    "First, let's prepare a dataset we can use to test our assumptions. In this case, we are going to use the popular MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ee5abef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: /workspace/data/\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = MNIST('/workspace/data/', download=True, transform=transforms.ToTensor())\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5a7a10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = 50_000\n",
    "n_valid = dataset.data.shape[0] - n_train\n",
    "x_train, y_train = dataset.data[:n_train, :, :].view(n_train, -1) / 255, dataset.targets[:n_train]\n",
    "x_valid, y_valid = dataset.data[n_train:, :, :].view(n_valid, -1) / 255, dataset.targets[n_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2687f4e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1310), tensor(0.3085))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mean, train_std = x_train.mean(), x_train.std()\n",
    "train_mean, train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b9eada5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x, m, s):\n",
    "    return (x - m) / s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cde70cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = normalize(x_train, train_mean, train_std)\n",
    "x_valid = normalize(x_valid, train_mean, train_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8918df",
   "metadata": {},
   "source": [
    "Since we are going to use an architecture that use convolutional layers, we are going to format the data using a `b,c,w,h` format. We know that images in the MNIST dataset are grayscale image of size 28x28. Thus, the training set should have a shape of `(50_000, 1, 28, 28)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd49c99e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([50000, 1, 28, 28]), torch.Size([10000, 1, 28, 28]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = x_train.view(-1, 1, 28, 28)\n",
    "x_valid = x_valid.view(-1, 1, 28, 28)\n",
    "x_train.shape, x_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93b1538d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, tensor(10))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n, *_ = x_train.shape\n",
    "c = y_train.max() + 1\n",
    "nh = 32\n",
    "n, c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb8eece",
   "metadata": {},
   "source": [
    "Let's create a `Conv2d` layer, and inspect its statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d57b52e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = nn.Conv2d(1, nh, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ee5add5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 1, 5, 5]), torch.Size([32]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1.weight.shape, l1.bias.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1585d445",
   "metadata": {},
   "source": [
    "The `Conv2d` layer we just created has 32 single-channel 5x5 filters, and we have one bias unit for every filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ddc5ac74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats(x):\n",
    "    return x.mean(), x.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57b3502e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor(-0.0039, grad_fn=<MeanBackward0>),\n",
       "  tensor(0.1187, grad_fn=<StdBackward0>)),\n",
       " (tensor(-0.0105, grad_fn=<MeanBackward0>),\n",
       "  tensor(0.1206, grad_fn=<StdBackward0>)))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats(l1.weight), stats(l1.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2089357d",
   "metadata": {},
   "source": [
    "The mean and std of the randomly initialized weights  and biases are centered at zero with a std around 0.11.\n",
    "\n",
    "What about the output activation? Let's try to pass the first 100 images of the validation set through the `Conv2d` layer..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "169e0b7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 1, 28, 28])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x_valid[:100]\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e936982a",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = l1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "255b5b9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.0201, grad_fn=<MeanBackward0>),\n",
       " tensor(0.6267, grad_fn=<StdBackward0>))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8335f82d",
   "metadata": {},
   "source": [
    "The mean is close to zero, but the std is not close to 1. This is not ideal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a4a4e8",
   "metadata": {},
   "source": [
    "### Kaiming normal\n",
    "\n",
    "Let's check if Kaiming normal works better. If you remember, Kaiming normal is designed to be used after a ReLU or Leaky ReLU layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9c62f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0minit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkaiming_normal_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0ma\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'fan_in'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnonlinearity\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'leaky_relu'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "\u001b[0;32mdef\u001b[0m \u001b[0mkaiming_normal_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'fan_in'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnonlinearity\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'leaky_relu'\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34mr\"\"\"Fills the input `Tensor` with values according to the method\u001b[0m\n",
       "\u001b[0;34m    described in `Delving deep into rectifiers: Surpassing human-level\u001b[0m\n",
       "\u001b[0;34m    performance on ImageNet classification` - He, K. et al. (2015), using a\u001b[0m\n",
       "\u001b[0;34m    normal distribution. The resulting tensor will have values sampled from\u001b[0m\n",
       "\u001b[0;34m    :math:`\\mathcal{N}(0, \\text{std}^2)` where\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    .. math::\u001b[0m\n",
       "\u001b[0;34m        \\text{std} = \\frac{\\text{gain}}{\\sqrt{\\text{fan\\_mode}}}\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Also known as He initialization.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Args:\u001b[0m\n",
       "\u001b[0;34m        tensor: an n-dimensional `torch.Tensor`\u001b[0m\n",
       "\u001b[0;34m        a: the negative slope of the rectifier used after this layer (only\u001b[0m\n",
       "\u001b[0;34m            used with ``'leaky_relu'``)\u001b[0m\n",
       "\u001b[0;34m        mode: either ``'fan_in'`` (default) or ``'fan_out'``. Choosing ``'fan_in'``\u001b[0m\n",
       "\u001b[0;34m            preserves the magnitude of the variance of the weights in the\u001b[0m\n",
       "\u001b[0;34m            forward pass. Choosing ``'fan_out'`` preserves the magnitudes in the\u001b[0m\n",
       "\u001b[0;34m            backwards pass.\u001b[0m\n",
       "\u001b[0;34m        nonlinearity: the non-linear function (`nn.functional` name),\u001b[0m\n",
       "\u001b[0;34m            recommended to use only with ``'relu'`` or ``'leaky_relu'`` (default).\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m    Examples:\u001b[0m\n",
       "\u001b[0;34m        >>> w = torch.empty(3, 5)\u001b[0m\n",
       "\u001b[0;34m        >>> nn.init.kaiming_normal_(w, mode='fan_out', nonlinearity='relu')\u001b[0m\n",
       "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Initializing zero-element tensors is a no-op\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_calculate_correct_fan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mgain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_gain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnonlinearity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgain\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      /usr/local/lib/python3.10/dist-packages/torch/nn/init.py\n",
       "\u001b[0;31mType:\u001b[0m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "init.kaiming_normal_??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3095755",
   "metadata": {},
   "source": [
    "What is `a`? The docstring says \"the negative slope of the rectifier used after this layer\". In other words, it is the slope of the activation function for every value below 0. For a linear function, such slope is 1. For a ReLU, the value is 0. For a Leaky ReLU, the value is generally 0.01."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3087799c",
   "metadata": {},
   "source": [
    "![what is a](../imgs/what_is_a.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1059499f",
   "metadata": {},
   "source": [
    "In this case, we are not using a non-linearity, thus a negative slope of `a=1` is appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78daadc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0120, grad_fn=<MeanBackward0>),\n",
       " tensor(1.0885, grad_fn=<StdBackward0>))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init.kaiming_normal_(l1.weight, a=1.)\n",
    "stats(l1(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418db05b",
   "metadata": {},
   "source": [
    "The variance of the output activation is now closer to 1. This is better than what we would have by using the default init method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d64498",
   "metadata": {},
   "source": [
    "One thing to notice is that when we tried Kaiming uniform, we used a value of `a=0`. Such value assumes a `ReLU` activation. Let's try to fix this mistake and set `a=1` also for Kaiming uniform. The resulting statistics for the output activation are better, although not as good as the one generated by Kaiming normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4cdb7efa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0069, grad_fn=<MeanBackward0>),\n",
       " tensor(1.0962, grad_fn=<StdBackward0>))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init.kaiming_uniform_(l1.weight, a=1.)\n",
    "stats(l1(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "89c35032",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(x, a=0):\n",
    "    return F.leaky_relu(l1(x), a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "27af6260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.5376, grad_fn=<MeanBackward0>),\n",
       " tensor(1.1020, grad_fn=<StdBackward0>))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init.kaiming_normal_(l1.weight, a=0)\n",
    "stats(f1(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285fef1d",
   "metadata": {},
   "source": [
    "The first thing to notice is that the mean is closer to 0.5 instead of 0. This is because we are using a ReLU activation, which convert every negative value to 0. Because of that, the mean will be closer to 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ae660894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.2195, grad_fn=<MeanBackward0>),\n",
       " tensor(0.3717, grad_fn=<StdBackward0>))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1 = nn.Conv2d(1, nh, 5)\n",
    "stats(f1(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4068925f",
   "metadata": {},
   "source": [
    "Remember that in the default init for every `Conv2d` layer, we are using `a=math.sqrt(5)`. As you can see, this value is highly suboptimal, as it leads to a mean far from 0.5 ― remember, we are using a ReLU so the mean is shifted towards 0.5 ― and the std is far from 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "159d35da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.4529, grad_fn=<MeanBackward0>),\n",
       " tensor(0.8546, grad_fn=<StdBackward0>))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1 = nn.Conv2d(1, nh, 5)\n",
    "init.kaiming_uniform_(l1.weight, a=0)\n",
    "stats(f1(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d723909a",
   "metadata": {},
   "source": [
    "Also in this case, the Kaiming uniform init performs similarly to Kaiming normal when initialized with the correct value of `a`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd24a437",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
