{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "836439c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06483020",
   "metadata": {},
   "source": [
    "## What is the role of the bias term in a neural network?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f713df",
   "metadata": {},
   "source": [
    "Let's build a very simple linear layer, that can optionally take a bias term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05b3be5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear(x, w, b=None, debug=False):\n",
    "    if b is not None:\n",
    "        a = (x @ w) + b\n",
    "    else:\n",
    "        a = (x @ w)\n",
    "    if debug:\n",
    "        print(a.shape)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4fe2a4",
   "metadata": {},
   "source": [
    "### Forward pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85afad8a",
   "metadata": {},
   "source": [
    "If we stack a few instances of this linear layer, the mean of the feature map computed after approximately 44 layers will have a mean and std equal to `nan`. This is called activation explosion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d4eaba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs, m = 1, 28 * 28\n",
    "nh = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b145c4e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.6582) tensor(25.3606)\n",
      "tensor(11.4425) tensor(156.2503)\n",
      "tensor(185.5521) tensor(1141.8094)\n",
      "tensor(1349.2837) tensor(6914.5078)\n",
      "tensor(6187.2715) tensor(48314.0352)\n",
      "tensor(620.2056) tensor(279270.5000)\n",
      "tensor(330917.7500) tensor(1975426.7500)\n",
      "tensor(1520116.5000) tensor(15572713.)\n",
      "tensor(27431668.) tensor(1.3274e+08)\n",
      "tensor(-1.8001e+08) tensor(1.0131e+09)\n",
      "tensor(-33159700.) tensor(5.9802e+09)\n",
      "tensor(7.1075e+08) tensor(4.1234e+10)\n",
      "tensor(5.2392e+10) tensor(3.0525e+11)\n",
      "tensor(-1.2567e+10) tensor(2.3668e+12)\n",
      "tensor(-2.0088e+12) tensor(1.4824e+13)\n",
      "tensor(-2.2484e+13) tensor(1.2909e+14)\n",
      "tensor(-4.0457e+13) tensor(8.5373e+14)\n",
      "tensor(-1.2641e+15) tensor(6.6426e+15)\n",
      "tensor(3.6104e+14) tensor(4.7668e+16)\n",
      "tensor(-1.0594e+16) tensor(3.7612e+17)\n",
      "tensor(9.7311e+15) tensor(2.6672e+18)\n",
      "tensor(-9.0080e+17) tensor(1.8061e+19)\n",
      "tensor(2.2738e+19) tensor(1.1207e+20)\n",
      "tensor(5.2459e+19) tensor(8.0268e+20)\n",
      "tensor(-2.9992e+20) tensor(6.5404e+21)\n",
      "tensor(6.4730e+21) tensor(3.8716e+22)\n",
      "tensor(-4.9422e+22) tensor(2.5076e+23)\n",
      "tensor(-3.0778e+23) tensor(1.6700e+24)\n",
      "tensor(-2.3320e+24) tensor(1.2221e+25)\n",
      "tensor(1.2968e+25) tensor(7.8227e+25)\n",
      "tensor(-5.0534e+25) tensor(5.8067e+26)\n",
      "tensor(9.4141e+26) tensor(4.0021e+27)\n",
      "tensor(-2.5247e+27) tensor(2.6951e+28)\n",
      "tensor(2.5281e+28) tensor(2.0463e+29)\n",
      "tensor(1.7547e+29) tensor(1.5507e+30)\n",
      "tensor(5.3218e+29) tensor(1.1000e+31)\n",
      "tensor(-1.7063e+31) tensor(7.8993e+31)\n",
      "tensor(-3.5832e+31) tensor(5.6147e+32)\n",
      "tensor(1.6856e+32) tensor(4.0200e+33)\n",
      "tensor(-6.3373e+33) tensor(2.7404e+34)\n",
      "tensor(-3.9972e+33) tensor(1.6862e+35)\n",
      "tensor(-2.1940e+34) tensor(1.0557e+36)\n",
      "tensor(3.4749e+34) tensor(6.5342e+36)\n",
      "tensor(inf) tensor(inf)\n",
      "Numerical instability at layer 43\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(bs, m)  # input image\n",
    "\n",
    "for i in range(100): \n",
    "    w = torch.randn(m, nh) if i == 0 else torch.randn(nh, nh)\n",
    "    \n",
    "    a = linear(a, w)\n",
    "    print(a.mean(), a.std())\n",
    "    \n",
    "    if torch.isinf(a.std()) or torch.isnan(a.std()):\n",
    "        print(f\"Numerical instability at layer {i}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d14765",
   "metadata": {},
   "source": [
    "Adding a bias term, unfortunately does not help in keeping the variance more numerically stable, and therefore does not seem to help in training deeper networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59cdce79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-4.5790) tensor(25.1622)\n",
      "tensor(22.9265) tensor(167.6310)\n",
      "tensor(-4.9820) tensor(1242.3936)\n",
      "tensor(1681.5902) tensor(8887.5879)\n",
      "tensor(-5290.4561) tensor(85838.1641)\n",
      "tensor(117315.8594) tensor(716983.6250)\n",
      "tensor(-460480.7500) tensor(5826601.5000)\n",
      "tensor(665238.7500) tensor(38150776.)\n",
      "tensor(-7813630.5000) tensor(2.8585e+08)\n",
      "tensor(-1.9672e+08) tensor(2.0505e+09)\n",
      "tensor(-2.6880e+09) tensor(1.5786e+10)\n",
      "tensor(2.4715e+10) tensor(1.0402e+11)\n",
      "tensor(8.2434e+10) tensor(8.1714e+11)\n",
      "tensor(-1.0596e+12) tensor(5.2401e+12)\n",
      "tensor(-5.7354e+12) tensor(3.2944e+13)\n",
      "tensor(8.1868e+13) tensor(2.6975e+14)\n",
      "tensor(-2.1753e+14) tensor(2.1331e+15)\n",
      "tensor(-1.5150e+15) tensor(1.4056e+16)\n",
      "tensor(2.8143e+16) tensor(1.0459e+17)\n",
      "tensor(-1.8545e+16) tensor(7.7766e+17)\n",
      "tensor(-1.6651e+17) tensor(5.5947e+18)\n",
      "tensor(-4.1283e+18) tensor(4.2637e+19)\n",
      "tensor(2.0435e+19) tensor(2.8666e+20)\n",
      "tensor(-4.3687e+20) tensor(1.9931e+21)\n",
      "tensor(8.7775e+20) tensor(1.3401e+22)\n",
      "tensor(-4.0719e+21) tensor(8.9700e+22)\n",
      "tensor(6.2608e+22) tensor(6.1837e+23)\n",
      "tensor(-7.6640e+23) tensor(4.0091e+24)\n",
      "tensor(1.0937e+24) tensor(3.0780e+25)\n",
      "tensor(-8.9474e+24) tensor(1.8583e+26)\n",
      "tensor(-3.5867e+25) tensor(1.3151e+27)\n",
      "tensor(5.2540e+26) tensor(8.8285e+27)\n",
      "tensor(6.8317e+26) tensor(5.3422e+28)\n",
      "tensor(4.7054e+28) tensor(3.9425e+29)\n",
      "tensor(-9.8977e+27) tensor(2.6428e+30)\n",
      "tensor(1.5044e+30) tensor(1.9789e+31)\n",
      "tensor(5.1043e+30) tensor(1.5055e+32)\n",
      "tensor(1.0277e+32) tensor(1.0641e+33)\n",
      "tensor(1.8305e+33) tensor(6.3496e+33)\n",
      "tensor(7.0010e+33) tensor(4.2127e+34)\n",
      "tensor(-8.3724e+34) tensor(2.7864e+35)\n",
      "tensor(-1.9149e+34) tensor(1.7889e+36)\n",
      "tensor(-1.5531e+36) tensor(1.0767e+37)\n",
      "tensor(-inf) tensor(inf)\n",
      "Numerical instability at layer 43\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(bs, m)  # input image\n",
    "\n",
    "for i in range(100): \n",
    "    w = torch.randn(m, nh) if i == 0 else torch.randn(nh, nh)\n",
    "    b = torch.randn(nh)\n",
    "\n",
    "    a = linear(a, w, b)\n",
    "    print(a.mean(), a.std())\n",
    "    if torch.isinf(a.std()) or torch.isnan(a.std()):\n",
    "        print(f\"Numerical instability at layer {i}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7fb8de",
   "metadata": {},
   "source": [
    "Note, however, how the mean and std of the feature maps generated by every layer are still very large. This network, despite being deeper, will not be able to learn much."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b95bb8f",
   "metadata": {},
   "source": [
    "### Is a good init sufficient to fix the issue?\n",
    "\n",
    "Improving the init, completely fixes the activation explosion issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6176f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0405) tensor(1.4605)\n",
      "tensor(-0.1080) tensor(1.0736)\n",
      "tensor(-0.2777) tensor(1.1102)\n",
      "tensor(-0.0034) tensor(1.0211)\n",
      "tensor(-0.1301) tensor(1.1686)\n",
      "tensor(-0.0411) tensor(1.0003)\n",
      "tensor(-0.0158) tensor(0.9847)\n",
      "tensor(-0.0138) tensor(0.9824)\n",
      "tensor(0.0689) tensor(1.0759)\n",
      "tensor(-0.0387) tensor(1.0492)\n",
      "tensor(-0.1385) tensor(1.0854)\n",
      "tensor(-0.0245) tensor(1.0515)\n",
      "tensor(-0.0124) tensor(1.1625)\n",
      "tensor(0.1718) tensor(1.1672)\n",
      "tensor(0.0484) tensor(0.8471)\n",
      "tensor(-0.0323) tensor(0.8489)\n",
      "tensor(-0.1236) tensor(0.9071)\n",
      "tensor(0.0276) tensor(0.9205)\n",
      "tensor(0.0013) tensor(1.0657)\n",
      "tensor(0.1014) tensor(1.0310)\n",
      "tensor(-0.2713) tensor(1.0612)\n",
      "tensor(0.0652) tensor(0.9682)\n",
      "tensor(0.1583) tensor(0.8461)\n",
      "tensor(0.1868) tensor(0.9837)\n",
      "tensor(-0.0121) tensor(0.9486)\n",
      "tensor(0.2276) tensor(1.0550)\n",
      "tensor(0.1102) tensor(1.0480)\n",
      "tensor(0.0410) tensor(1.0528)\n",
      "tensor(-0.1705) tensor(0.9793)\n",
      "tensor(-0.2110) tensor(1.0383)\n",
      "tensor(-0.0044) tensor(1.0173)\n",
      "tensor(0.0357) tensor(0.9955)\n",
      "tensor(-0.0852) tensor(1.1974)\n",
      "tensor(-0.1136) tensor(0.9668)\n",
      "tensor(0.2694) tensor(0.8961)\n",
      "tensor(0.0574) tensor(0.8979)\n",
      "tensor(-0.1741) tensor(0.8807)\n",
      "tensor(-0.0978) tensor(1.0756)\n",
      "tensor(-0.1307) tensor(1.0130)\n",
      "tensor(0.1808) tensor(1.1617)\n",
      "tensor(0.0217) tensor(0.9941)\n",
      "tensor(-0.0190) tensor(0.9984)\n",
      "tensor(0.1232) tensor(1.0683)\n",
      "tensor(-0.0265) tensor(1.2611)\n",
      "tensor(-0.0623) tensor(1.1867)\n",
      "tensor(-0.0370) tensor(0.9510)\n",
      "tensor(-0.0703) tensor(0.9574)\n",
      "tensor(-0.0918) tensor(1.0402)\n",
      "tensor(0.0250) tensor(1.1631)\n",
      "tensor(0.0405) tensor(1.1539)\n",
      "tensor(-0.0508) tensor(1.1323)\n",
      "tensor(0.0226) tensor(0.9847)\n",
      "tensor(0.0610) tensor(1.0344)\n",
      "tensor(-0.0004) tensor(0.9553)\n",
      "tensor(0.0480) tensor(1.1378)\n",
      "tensor(0.1450) tensor(1.0136)\n",
      "tensor(-0.0572) tensor(0.9801)\n",
      "tensor(0.2026) tensor(1.0037)\n",
      "tensor(-0.1996) tensor(0.8792)\n",
      "tensor(-0.0397) tensor(1.1768)\n",
      "tensor(0.1467) tensor(1.0848)\n",
      "tensor(0.1179) tensor(1.1571)\n",
      "tensor(-0.2092) tensor(0.9904)\n",
      "tensor(0.1920) tensor(1.0852)\n",
      "tensor(0.1324) tensor(1.0441)\n",
      "tensor(0.1528) tensor(1.1770)\n",
      "tensor(0.0601) tensor(1.1765)\n",
      "tensor(-0.2239) tensor(0.9805)\n",
      "tensor(0.1783) tensor(1.0642)\n",
      "tensor(-0.1073) tensor(1.0169)\n",
      "tensor(0.0753) tensor(1.1412)\n",
      "tensor(0.1129) tensor(1.0145)\n",
      "tensor(-0.1859) tensor(1.0346)\n",
      "tensor(0.1169) tensor(0.9473)\n",
      "tensor(-0.1912) tensor(1.0636)\n",
      "tensor(-0.0079) tensor(1.0073)\n",
      "tensor(0.0337) tensor(0.9432)\n",
      "tensor(0.1897) tensor(1.2292)\n",
      "tensor(-0.0239) tensor(1.0322)\n",
      "tensor(0.1852) tensor(1.0324)\n",
      "tensor(-0.0109) tensor(1.2096)\n",
      "tensor(0.1497) tensor(1.0295)\n",
      "tensor(-0.0589) tensor(1.0446)\n",
      "tensor(0.2507) tensor(1.0407)\n",
      "tensor(0.1101) tensor(0.9210)\n",
      "tensor(-0.0436) tensor(0.9111)\n",
      "tensor(0.2377) tensor(0.8932)\n",
      "tensor(-0.0990) tensor(1.0106)\n",
      "tensor(-0.0149) tensor(1.1402)\n",
      "tensor(-0.0249) tensor(0.9738)\n",
      "tensor(0.1984) tensor(0.9895)\n",
      "tensor(0.0349) tensor(1.0329)\n",
      "tensor(0.0665) tensor(0.8636)\n",
      "tensor(0.0832) tensor(1.1653)\n",
      "tensor(-0.0153) tensor(0.8224)\n",
      "tensor(0.1616) tensor(0.9683)\n",
      "tensor(-0.0658) tensor(1.1236)\n",
      "tensor(0.1487) tensor(1.2721)\n",
      "tensor(8.3313e-05) tensor(1.0597)\n",
      "tensor(0.0358) tensor(1.0652)\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(bs, m)  # input image\n",
    "\n",
    "for i in range(100): \n",
    "    w = torch.randn(m, nh) / math.sqrt(m) if i == 0 else torch.randn(nh, nh) / math.sqrt(m)  # xavier init\n",
    "    b = torch.randn(nh)\n",
    "\n",
    "    a = linear(a, w, b)\n",
    "    print(a.mean(), a.std())\n",
    "    if torch.isinf(a.std()) or torch.isnan(a.std()):\n",
    "        print(f\"Numerical instability at layer {i}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba1ddb8",
   "metadata": {},
   "source": [
    "Let's do an ablation study and try Xavier init without using the bias term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ebf4aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0287) tensor(0.9324)\n",
      "tensor(-0.0291) tensor(0.2501)\n",
      "tensor(0.0012) tensor(0.0751)\n",
      "tensor(-9.2146e-05) tensor(0.0215)\n",
      "tensor(-0.0005) tensor(0.0053)\n",
      "tensor(0.0002) tensor(0.0015)\n",
      "tensor(0.0001) tensor(0.0004)\n",
      "tensor(-1.4655e-05) tensor(9.0919e-05)\n",
      "tensor(7.6926e-08) tensor(2.1277e-05)\n",
      "tensor(5.4413e-07) tensor(5.6696e-06)\n",
      "tensor(-2.5233e-08) tensor(1.5630e-06)\n",
      "tensor(-4.9312e-08) tensor(3.6550e-07)\n",
      "tensor(-1.0862e-08) tensor(9.0942e-08)\n",
      "tensor(4.8076e-09) tensor(2.1733e-08)\n",
      "tensor(6.8163e-10) tensor(5.7634e-09)\n",
      "tensor(1.2298e-10) tensor(1.3088e-09)\n",
      "tensor(-4.0085e-11) tensor(3.2561e-10)\n",
      "tensor(-9.4507e-12) tensor(1.0271e-10)\n",
      "tensor(4.5394e-12) tensor(2.3110e-11)\n",
      "tensor(-6.9884e-13) tensor(6.0443e-12)\n",
      "tensor(2.3810e-14) tensor(1.6117e-12)\n",
      "tensor(-8.4391e-14) tensor(3.6230e-13)\n",
      "tensor(8.3668e-15) tensor(1.0140e-13)\n",
      "tensor(2.4415e-15) tensor(2.9122e-14)\n",
      "tensor(-1.3079e-15) tensor(7.3537e-15)\n",
      "tensor(-2.1614e-16) tensor(1.8758e-15)\n",
      "tensor(1.6323e-17) tensor(4.8513e-16)\n",
      "tensor(-3.0096e-17) tensor(1.1880e-16)\n",
      "tensor(1.0506e-20) tensor(3.3886e-17)\n",
      "tensor(1.0409e-19) tensor(8.4879e-18)\n",
      "tensor(3.9351e-20) tensor(2.2936e-18)\n",
      "tensor(-6.3671e-20) tensor(5.8573e-19)\n",
      "tensor(5.9752e-21) tensor(1.3038e-19)\n",
      "tensor(-7.9670e-21) tensor(2.9595e-20)\n",
      "tensor(-8.2315e-22) tensor(7.4628e-21)\n",
      "tensor(-3.4743e-23) tensor(1.7681e-21)\n",
      "tensor(4.9205e-23) tensor(4.0537e-22)\n",
      "tensor(2.3386e-23) tensor(9.8268e-23)\n",
      "tensor(-2.5621e-25) tensor(2.2418e-23)\n",
      "tensor(-1.0569e-24) tensor(4.9468e-24)\n",
      "tensor(9.4271e-26) tensor(1.1204e-24)\n",
      "tensor(-8.2299e-27) tensor(2.9339e-25)\n",
      "tensor(-7.3331e-27) tensor(7.8340e-26)\n",
      "tensor(1.0756e-27) tensor(2.2481e-26)\n",
      "tensor(6.0698e-28) tensor(6.9108e-27)\n",
      "tensor(7.8114e-30) tensor(1.8460e-27)\n",
      "tensor(-1.9794e-29) tensor(3.6441e-28)\n",
      "tensor(-1.4871e-29) tensor(9.5137e-29)\n",
      "tensor(4.4692e-30) tensor(2.3702e-29)\n",
      "tensor(6.5479e-32) tensor(6.0257e-30)\n",
      "tensor(6.8464e-32) tensor(1.5064e-30)\n",
      "tensor(2.8605e-32) tensor(4.0056e-31)\n",
      "tensor(1.6646e-32) tensor(9.4103e-32)\n",
      "tensor(-7.9270e-34) tensor(2.6319e-32)\n",
      "tensor(-4.6085e-34) tensor(6.2008e-33)\n",
      "tensor(-3.6758e-35) tensor(1.8135e-33)\n",
      "tensor(3.5460e-35) tensor(4.7051e-34)\n",
      "tensor(3.1175e-36) tensor(1.2177e-34)\n",
      "tensor(4.6289e-37) tensor(3.1193e-35)\n",
      "tensor(1.8499e-37) tensor(8.7355e-36)\n",
      "tensor(-4.4251e-37) tensor(2.1604e-36)\n",
      "tensor(9.5653e-38) tensor(5.2664e-37)\n",
      "tensor(1.5811e-38) tensor(1.6931e-37)\n",
      "tensor(-2.1319e-39) tensor(3.8590e-38)\n",
      "tensor(3.8629e-40) tensor(1.0171e-38)\n",
      "tensor(4.5697e-40) tensor(2.6724e-39)\n",
      "tensor(7.7007e-41) tensor(5.9123e-40)\n",
      "tensor(-6.3241e-42) tensor(1.2576e-40)\n",
      "tensor(6.4095e-42) tensor(2.9675e-41)\n",
      "tensor(7.4269e-43) tensor(6.8299e-42)\n",
      "tensor(-1.9618e-43) tensor(1.7124e-42)\n",
      "tensor(-2.8026e-45) tensor(4.3580e-43)\n",
      "tensor(2.8026e-45) tensor(1.1631e-43)\n",
      "tensor(-8.4078e-45) tensor(3.3631e-44)\n",
      "tensor(-1.4013e-45) tensor(9.8091e-45)\n",
      "tensor(0.) tensor(2.8026e-45)\n",
      "tensor(0.) tensor(0.)\n",
      "tensor(0.) tensor(0.)\n",
      "tensor(0.) tensor(0.)\n",
      "tensor(0.) tensor(0.)\n",
      "tensor(0.) tensor(0.)\n",
      "tensor(0.) tensor(0.)\n",
      "tensor(0.) tensor(0.)\n",
      "tensor(0.) tensor(0.)\n",
      "tensor(0.) tensor(0.)\n",
      "tensor(0.) tensor(0.)\n",
      "tensor(0.) tensor(0.)\n",
      "tensor(0.) tensor(0.)\n",
      "tensor(0.) tensor(0.)\n",
      "tensor(0.) tensor(0.)\n",
      "tensor(0.) tensor(0.)\n",
      "tensor(0.) tensor(0.)\n",
      "tensor(0.) tensor(0.)\n",
      "tensor(0.) tensor(0.)\n",
      "tensor(0.) tensor(0.)\n",
      "tensor(0.) tensor(0.)\n",
      "tensor(0.) tensor(0.)\n",
      "tensor(0.) tensor(0.)\n",
      "tensor(0.) tensor(0.)\n",
      "tensor(0.) tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(bs, m)  # input image\n",
    "\n",
    "for i in range(100): \n",
    "    w = torch.randn(m, nh) / math.sqrt(m) if i == 0 else torch.randn(nh, nh) / math.sqrt(m)\n",
    "\n",
    "    a = linear(a, w)\n",
    "    print(a.mean(), a.std())\n",
    "    if torch.isinf(a.std()) or torch.isnan(a.std()):\n",
    "        print(f\"Numerical instability at layer {i}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcdb714",
   "metadata": {},
   "source": [
    "Removing the bias term shows that just a good init is not enough. The purpose of the bias term is to improve numerical stability in the forward pass. Without a bias term, it is harder to train deep architectures.\n",
    "\n",
    "In each layer of the forward pass, we are multiplying the previous layer's output activation by a set of weights close to zero. Repeating this step multiple times will lead to a set of output activation with a std so small that it clamps to `nan`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "744201f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.01, 0.0001, 1.0000000000000002e-06)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 * 0.01, 1 * 0.01 * 0.01, 1 * 0.01 * 0.01 * 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4317cb9a",
   "metadata": {},
   "source": [
    "### TODO\n",
    "\n",
    "- [ ] Does Xavier init make any assumption about the bias term?\n",
    "- [ ] Plot activations for each layer\n",
    "- [ ] Backward pass\n",
    "- [ ] BatchNorm\n",
    "- [ ] ReLu\n",
    "- [ ] Conv layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b322cc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
