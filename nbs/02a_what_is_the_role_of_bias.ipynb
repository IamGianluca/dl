{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31a9b9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c636061",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15cd01f4",
   "metadata": {},
   "source": [
    "## What is the role of the bias term in a neural network?\n",
    "\n",
    "Let's build a very simple linear layer, that can optionally take a bias term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09b17aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin(x, w, b=None, debug=False):\n",
    "    if debug:\n",
    "        print(x.shape, w.shape, b.shape)\n",
    "    if b is not None:\n",
    "        return (x @ w) + b\n",
    "    else:\n",
    "        return x @ w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bd1a0d",
   "metadata": {},
   "source": [
    "If we stack a few instances of this linear layer, the mean of the feature map computed after just two layers will have a mean very far from zero and inf/nan std. This is called activation explosion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b121718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0630) tensor(21.4497)\n",
      "tensor(-169.5533) tensor(nan)\n",
      "Numerical instability at layer 1\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(512,512)  # input image\n",
    "\n",
    "for i in range(100): \n",
    "    w = torch.randn(512)  # init weights for layer i\n",
    "    \n",
    "    a = lin(a, w)\n",
    "    print(a.mean(), a.std())\n",
    "    if torch.isinf(a.std()) or torch.isnan(a.std()):\n",
    "        print(f\"Numerical instability at layer {i}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03948199",
   "metadata": {},
   "source": [
    "The bias term helps to keep the variance more numerically stable, thus allowing us to train deeper networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e075282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1425) tensor(22.2082)\n",
      "tensor(7.0174) tensor(0.)\n",
      "tensor(-67.3624) tensor(2.2911e-05)\n",
      "tensor(110.9664) tensor(2.2911e-05)\n",
      "tensor(1554.6863) tensor(0.)\n",
      "tensor(-21929.1367) tensor(0.)\n",
      "tensor(130204.3828) tensor(0.0235)\n",
      "tensor(-811657.5625) tensor(0.0626)\n",
      "tensor(21114270.) tensor(4.0039)\n",
      "tensor(2.1871e+08) tensor(16.0156)\n",
      "tensor(6.2728e+09) tensor(512.5007)\n",
      "tensor(-1.4847e+11) tensor(0.)\n",
      "tensor(1.2078e+11) tensor(0.)\n",
      "tensor(1.7717e+12) tensor(524800.7500)\n",
      "tensor(-2.8269e+13) tensor(8396812.)\n",
      "tensor(-5.0848e+14) tensor(2.0152e+08)\n",
      "tensor(-1.9954e+15) tensor(4.0305e+08)\n",
      "tensor(1.2028e+16) tensor(0.)\n",
      "tensor(3.7500e+17) tensor(0.)\n",
      "tensor(2.9286e+18) tensor(2.7515e+11)\n",
      "tensor(3.0962e+19) tensor(8.8047e+12)\n",
      "tensor(4.1758e+20) tensor(3.5219e+13)\n",
      "tensor(8.0624e+21) tensor(5.6350e+14)\n",
      "tensor(-7.9024e+22) tensor(0.)\n",
      "tensor(1.3301e+24) tensor(0.)\n",
      "tensor(-3.1645e+24) tensor(8.6554e+17)\n",
      "tensor(-7.6284e+25) tensor(2.7697e+19)\n",
      "tensor(5.1303e+26) tensor(1.4772e+20)\n",
      "tensor(-1.5459e+28) tensor(3.5452e+21)\n",
      "tensor(6.1447e+28) tensor(4.7270e+21)\n",
      "tensor(-1.9656e+30) tensor(1.5126e+23)\n",
      "tensor(5.5206e+31) tensor(1.4521e+25)\n",
      "tensor(-1.8149e+32) tensor(1.9362e+25)\n",
      "tensor(2.7068e+32) tensor(7.7447e+25)\n",
      "tensor(2.3412e+33) tensor(9.2936e+26)\n",
      "tensor(2.3880e+34) tensor(0.)\n",
      "tensor(1.4487e+35) tensor(9.9132e+27)\n",
      "tensor(inf) tensor(inf)\n",
      "Numerical instability at layer 37\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(512,512)  # input image\n",
    "\n",
    "\n",
    "for i in range(100): \n",
    "    w = torch.randn(512)\n",
    "    b = torch.zeros(512)\n",
    "\n",
    "    a = lin(a, w, b)\n",
    "    print(a.mean(), a.std())\n",
    "    if torch.isinf(a.std()) or torch.isnan(a.std()):\n",
    "        print(f\"Numerical instability at layer {i}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3c5189",
   "metadata": {},
   "source": [
    "Note, however, how the mean and std of the feature maps generate by every layer are still very large. This network, despite being deeper, will not be able to learn much."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5ff17a",
   "metadata": {},
   "source": [
    "## Is good init sufficient to fix the issue?\n",
    "\n",
    "Improving the init further helps delaying the activation explosion issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "746e1995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0601) tensor(0.9640)\n",
      "tensor(1.2635) tensor(0.)\n",
      "tensor(-1.6608) tensor(2.3865e-07)\n",
      "tensor(-1.7729) tensor(1.1933e-07)\n",
      "tensor(4.8575) tensor(9.5461e-07)\n",
      "tensor(1.2564) tensor(3.5798e-07)\n",
      "tensor(-1.3141) tensor(1.1933e-07)\n",
      "tensor(-0.8528) tensor(1.7899e-07)\n",
      "tensor(-0.5903) tensor(1.7899e-07)\n",
      "tensor(-0.3502) tensor(8.9494e-08)\n",
      "tensor(0.1527) tensor(0.)\n",
      "tensor(0.1190) tensor(2.2374e-08)\n",
      "tensor(-0.0290) tensor(0.)\n",
      "tensor(-0.0472) tensor(1.1187e-08)\n",
      "tensor(-0.0199) tensor(1.8645e-09)\n",
      "tensor(-0.0005) tensor(0.)\n",
      "tensor(0.0005) tensor(8.7397e-11)\n",
      "tensor(-0.0006) tensor(1.7479e-10)\n",
      "tensor(0.0002) tensor(0.)\n",
      "tensor(-0.0002) tensor(1.4566e-11)\n",
      "tensor(0.0002) tensor(1.4566e-11)\n",
      "tensor(0.0002) tensor(8.7397e-11)\n",
      "tensor(0.0006) tensor(1.7479e-10)\n",
      "tensor(5.2908e-05) tensor(0.)\n",
      "tensor(-6.2868e-05) tensor(2.1849e-11)\n",
      "tensor(2.4735e-05) tensor(1.8208e-12)\n",
      "tensor(-6.6639e-06) tensor(1.8208e-12)\n",
      "tensor(-6.3730e-06) tensor(4.5519e-13)\n",
      "tensor(-9.1494e-06) tensor(0.)\n",
      "tensor(-4.9633e-06) tensor(4.5519e-13)\n",
      "tensor(-3.0145e-06) tensor(0.)\n",
      "tensor(7.6855e-06) tensor(9.1038e-13)\n",
      "tensor(1.3791e-05) tensor(2.7312e-12)\n",
      "tensor(-2.3269e-05) tensor(5.4623e-12)\n",
      "tensor(3.9413e-05) tensor(3.6415e-12)\n",
      "tensor(3.0135e-05) tensor(5.4623e-12)\n",
      "tensor(2.8669e-06) tensor(2.2760e-13)\n",
      "tensor(4.0799e-07) tensor(2.8450e-14)\n",
      "tensor(-2.5841e-08) tensor(0.)\n",
      "tensor(-4.4932e-09) tensor(4.4452e-16)\n",
      "tensor(-5.9226e-09) tensor(4.4452e-16)\n",
      "tensor(-3.1874e-09) tensor(4.4452e-16)\n",
      "tensor(5.3312e-10) tensor(5.5565e-17)\n",
      "tensor(-3.3212e-10) tensor(0.)\n",
      "tensor(3.2579e-10) tensor(2.7783e-17)\n",
      "tensor(3.9358e-10) tensor(0.)\n",
      "tensor(7.2131e-10) tensor(0.)\n",
      "tensor(8.4976e-10) tensor(2.2226e-16)\n",
      "tensor(-1.8076e-09) tensor(5.5565e-16)\n",
      "tensor(4.2625e-10) tensor(0.)\n",
      "tensor(-1.7385e-10) tensor(0.)\n",
      "tensor(-4.7039e-11) tensor(1.0419e-17)\n",
      "tensor(-4.1299e-11) tensor(0.)\n",
      "tensor(2.3227e-11) tensor(1.7364e-18)\n",
      "tensor(-5.2205e-11) tensor(1.7364e-17)\n",
      "tensor(3.4207e-11) tensor(0.)\n",
      "tensor(5.0187e-11) tensor(1.3891e-17)\n",
      "tensor(-4.6294e-11) tensor(3.4728e-18)\n",
      "tensor(2.8861e-11) tensor(6.9457e-18)\n",
      "tensor(-6.4765e-12) tensor(0.)\n",
      "tensor(5.9263e-12) tensor(0.)\n",
      "tensor(7.0879e-12) tensor(1.3023e-18)\n",
      "tensor(-5.5196e-12) tensor(4.3411e-19)\n",
      "tensor(-4.0807e-12) tensor(4.3411e-19)\n",
      "tensor(1.0338e-12) tensor(1.0853e-19)\n",
      "tensor(6.5741e-13) tensor(5.4263e-20)\n",
      "tensor(-1.3236e-12) tensor(1.0853e-19)\n",
      "tensor(-3.2140e-12) tensor(6.5116e-19)\n",
      "tensor(-4.1664e-12) tensor(1.3023e-18)\n",
      "tensor(-3.2397e-12) tensor(0.)\n",
      "tensor(9.5713e-13) tensor(1.0853e-19)\n",
      "tensor(1.0264e-12) tensor(0.)\n",
      "tensor(-1.5363e-13) tensor(4.0697e-20)\n",
      "tensor(-4.3252e-13) tensor(0.)\n",
      "tensor(3.2297e-13) tensor(2.7132e-20)\n",
      "tensor(-2.7752e-13) tensor(2.7132e-20)\n",
      "tensor(4.3153e-13) tensor(1.3566e-19)\n",
      "tensor(1.6478e-14) tensor(0.)\n",
      "tensor(-5.7956e-15) tensor(1.6957e-21)\n",
      "tensor(-3.6667e-15) tensor(1.2718e-21)\n",
      "tensor(2.3952e-16) tensor(7.9487e-23)\n",
      "tensor(-4.7936e-17) tensor(3.3120e-24)\n",
      "tensor(-7.1535e-18) tensor(0.)\n",
      "tensor(8.0469e-18) tensor(8.2799e-25)\n",
      "tensor(-3.3173e-18) tensor(8.2799e-25)\n",
      "tensor(-2.0670e-18) tensor(4.1399e-25)\n",
      "tensor(2.2026e-18) tensor(0.)\n",
      "tensor(4.8345e-18) tensor(4.1399e-25)\n",
      "tensor(3.2227e-18) tensor(6.2099e-25)\n",
      "tensor(3.0651e-18) tensor(8.2799e-25)\n",
      "tensor(-1.9770e-18) tensor(2.0700e-25)\n",
      "tensor(-8.5794e-19) tensor(2.0700e-25)\n",
      "tensor(-7.1780e-20) tensor(6.4687e-27)\n",
      "tensor(1.4467e-19) tensor(2.5875e-26)\n",
      "tensor(1.9617e-19) tensor(5.1749e-26)\n",
      "tensor(2.6361e-19) tensor(2.5875e-26)\n",
      "tensor(1.0889e-19) tensor(2.5875e-26)\n",
      "tensor(-3.2583e-20) tensor(6.4687e-27)\n",
      "tensor(1.8791e-20) tensor(1.6172e-27)\n",
      "tensor(-1.7412e-21) tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(512,512)  # input image\n",
    "\n",
    "for i in range(100): \n",
    "    # init params for every layer\n",
    "    w = torch.randn(512) / math.sqrt(512)  # xavier init\n",
    "    b = torch.zeros(512)\n",
    "\n",
    "    a = lin(a, w, b)\n",
    "    print(a.mean(), a.std())\n",
    "    if torch.isinf(a.std()) or torch.isnan(a.std()):\n",
    "        print(f\"Numerical instability at layer {i}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42527817",
   "metadata": {},
   "source": [
    "Let's do an ablation study and try Xavier init without using the bias term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79e5503e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0239) tensor(0.9825)\n",
      "tensor(-1.1993) tensor(nan)\n",
      "Numerical instability at layer 1\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(512,512)  # input image\n",
    "\n",
    "for i in range(100): \n",
    "    w = torch.randn(512) / math.sqrt(512)  # xavier init\n",
    "\n",
    "    a = lin(a, w)\n",
    "    print(a.mean(), a.std())\n",
    "    if torch.isinf(a.std()) or torch.isnan(a.std()):\n",
    "        print(f\"Numerical instability at layer {i}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ffcec1",
   "metadata": {},
   "source": [
    "Removing the bias term shows that just a good init is not enough. The purpose of the bias term is to improve numerical stability in the forward pass. Without a bias term, it is harder to train deep architectures."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
