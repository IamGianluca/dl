{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f553851c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44109737",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8863966",
   "metadata": {},
   "source": [
    "## What is the role of the bias term in a neural network?\n",
    "\n",
    "Let's build a very simple linear layer, that can optionally take a bias term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b05bd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin(x, w, b=None, debug=False):\n",
    "    if debug:\n",
    "        print(x.shape, w.shape, b.shape)\n",
    "    if b is not None:\n",
    "        return (x @ w) + b\n",
    "    else:\n",
    "        return x @ w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fc7207",
   "metadata": {},
   "source": [
    "If we stack a few instances of this linear layer, the mean of the feature map computed after just two layers will have a mean very far from zero and inf/nan std. This is called activation explosion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "20623324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.6111) tensor(22.8972)\n",
      "tensor(-719.8424) tensor(nan)\n",
      "Numerical instability at layer 1\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(512,512)  # input image\n",
    "\n",
    "for i in range(100): \n",
    "    w = torch.randn(512)  # init weights for layer i\n",
    "    \n",
    "    a = lin(a, w)\n",
    "    print(a.mean(), a.std())\n",
    "    if torch.isinf(a.std()) or torch.isnan(a.std()):\n",
    "        print(f\"Numerical instability at layer {i}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7a331f",
   "metadata": {},
   "source": [
    "The bias term helps to keep the variance more numerically stable, thus allowing us to train deeper networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3b864c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3053) tensor(21.7885)\n",
      "tensor(78.3094) tensor(0.)\n",
      "tensor(-587.9160) tensor(0.)\n",
      "tensor(-20112.5020) tensor(0.)\n",
      "tensor(51898.5625) tensor(0.)\n",
      "tensor(-123345.1250) tensor(0.)\n",
      "tensor(-1790769.7500) tensor(0.3754)\n",
      "tensor(-35605408.) tensor(0.)\n",
      "tensor(-96858832.) tensor(8.0078)\n",
      "tensor(-2.3924e+09) tensor(512.5007)\n",
      "tensor(6.5086e+09) tensor(0.)\n",
      "tensor(2.3188e+09) tensor(0.)\n",
      "tensor(-5.6051e+10) tensor(16400.0234)\n",
      "tensor(9.9710e+11) tensor(65600.0938)\n",
      "tensor(-5.0624e+11) tensor(0.)\n",
      "tensor(1.3642e+13) tensor(0.)\n",
      "tensor(3.6873e+14) tensor(0.)\n",
      "tensor(-1.9596e+15) tensor(4.0305e+08)\n",
      "tensor(-1.4032e+16) tensor(0.)\n",
      "tensor(-1.7219e+16) tensor(1.0748e+09)\n",
      "tensor(3.8877e+17) tensor(3.4393e+10)\n",
      "tensor(-6.3708e+18) tensor(0.)\n",
      "tensor(-2.6871e+20) tensor(0.)\n",
      "tensor(-5.3975e+20) tensor(0.)\n",
      "tensor(-5.6857e+21) tensor(0.)\n",
      "tensor(-1.7724e+23) tensor(3.6064e+16)\n",
      "tensor(6.9813e+24) tensor(5.7702e+17)\n",
      "tensor(-1.6895e+25) tensor(3.4621e+18)\n",
      "tensor(-5.8620e+26) tensor(1.4772e+20)\n",
      "tensor(-4.6679e+26) tensor(0.)\n",
      "tensor(-1.4751e+28) tensor(1.1817e+21)\n",
      "tensor(1.3910e+28) tensor(0.)\n",
      "tensor(4.4458e+28) tensor(1.4181e+22)\n",
      "tensor(3.9333e+29) tensor(0.)\n",
      "tensor(-4.4505e+30) tensor(3.0253e+23)\n",
      "tensor(-3.9921e+31) tensor(9.6809e+24)\n",
      "tensor(5.3226e+32) tensor(0.)\n",
      "tensor(-2.1675e+33) tensor(4.6468e+26)\n",
      "tensor(1.0135e+34) tensor(0.)\n",
      "tensor(-3.0441e+35) tensor(7.9306e+28)\n",
      "tensor(inf) tensor(inf)\n",
      "Numerical instability at layer 40\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(512,512)  # input image\n",
    "\n",
    "\n",
    "for i in range(100): \n",
    "    w = torch.randn(512)\n",
    "    b = torch.zeros(512)\n",
    "\n",
    "    a = lin(a, w, b)\n",
    "    print(a.mean(), a.std())\n",
    "    if torch.isinf(a.std()) or torch.isnan(a.std()):\n",
    "        print(f\"Numerical instability at layer {i}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49134338",
   "metadata": {},
   "source": [
    "Note, however, how the mean and std of the feature maps generate by every layer are still very large. This network, despite being deeper, will not be able to learn much."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a489168e",
   "metadata": {},
   "source": [
    "## Is good init sufficient to fix the issue?\n",
    "\n",
    "Improving the init further helps delaying the activation explosion issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "999a7079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0038) tensor(1.0265)\n",
      "tensor(0.4211) tensor(1.4916e-07)\n",
      "tensor(0.6980) tensor(0.)\n",
      "tensor(0.0290) tensor(1.1187e-08)\n",
      "tensor(-0.0189) tensor(1.8645e-09)\n",
      "tensor(0.0026) tensor(6.9918e-10)\n",
      "tensor(-0.0021) tensor(6.9918e-10)\n",
      "tensor(-0.0001) tensor(0.)\n",
      "tensor(-8.8191e-05) tensor(7.2831e-12)\n",
      "tensor(8.8952e-06) tensor(2.7312e-12)\n",
      "tensor(7.2592e-06) tensor(4.5519e-13)\n",
      "tensor(2.9686e-06) tensor(2.2760e-13)\n",
      "tensor(4.9048e-06) tensor(0.)\n",
      "tensor(8.9878e-06) tensor(0.)\n",
      "tensor(7.3327e-07) tensor(0.)\n",
      "tensor(-4.6926e-07) tensor(8.5349e-14)\n",
      "tensor(-1.0211e-06) tensor(0.)\n",
      "tensor(4.9381e-07) tensor(0.)\n",
      "tensor(1.6887e-07) tensor(0.)\n",
      "tensor(3.1682e-08) tensor(3.5562e-15)\n",
      "tensor(-2.0901e-08) tensor(1.7781e-15)\n",
      "tensor(-6.5610e-09) tensor(1.7781e-15)\n",
      "tensor(-5.0126e-09) tensor(0.)\n",
      "tensor(-1.1444e-08) tensor(8.8905e-16)\n",
      "tensor(2.0539e-08) tensor(3.5562e-15)\n",
      "tensor(4.3722e-09) tensor(0.)\n",
      "tensor(-7.8328e-11) tensor(0.)\n",
      "tensor(-1.5745e-11) tensor(0.)\n",
      "tensor(-7.1695e-12) tensor(1.3023e-18)\n",
      "tensor(3.5638e-12) tensor(0.)\n",
      "tensor(4.4156e-12) tensor(8.6821e-19)\n",
      "tensor(2.3715e-12) tensor(2.1705e-19)\n",
      "tensor(4.2373e-13) tensor(0.)\n",
      "tensor(7.2031e-14) tensor(6.7829e-21)\n",
      "tensor(-3.2792e-14) tensor(0.)\n",
      "tensor(5.8642e-14) tensor(6.7829e-21)\n",
      "tensor(2.3778e-14) tensor(5.0872e-21)\n",
      "tensor(-1.4307e-14) tensor(1.6957e-21)\n",
      "tensor(-2.7211e-14) tensor(5.0872e-21)\n",
      "tensor(-2.3096e-14) tensor(0.)\n",
      "tensor(1.8334e-14) tensor(1.6957e-21)\n",
      "tensor(-1.6204e-14) tensor(0.)\n",
      "tensor(2.5368e-14) tensor(8.4786e-21)\n",
      "tensor(-3.1763e-14) tensor(6.7829e-21)\n",
      "tensor(-1.0667e-14) tensor(2.5436e-21)\n",
      "tensor(-6.2034e-15) tensor(4.2393e-22)\n",
      "tensor(-9.7855e-15) tensor(8.4786e-22)\n",
      "tensor(2.7839e-15) tensor(2.1197e-22)\n",
      "tensor(-2.7616e-15) tensor(2.1197e-22)\n",
      "tensor(-1.8060e-15) tensor(0.)\n",
      "tensor(-3.6990e-16) tensor(7.9487e-23)\n",
      "tensor(5.2022e-16) tensor(0.)\n",
      "tensor(-3.5305e-16) tensor(2.6496e-23)\n",
      "tensor(1.2633e-15) tensor(0.)\n",
      "tensor(4.5779e-16) tensor(1.0598e-22)\n",
      "tensor(-3.2742e-16) tensor(2.6496e-23)\n",
      "tensor(-1.2753e-17) tensor(0.)\n",
      "tensor(1.6959e-18) tensor(0.)\n",
      "tensor(-2.3168e-19) tensor(0.)\n",
      "tensor(4.9132e-19) tensor(5.1749e-26)\n",
      "tensor(7.5783e-19) tensor(1.0350e-25)\n",
      "tensor(4.6276e-19) tensor(1.5525e-25)\n",
      "tensor(-8.8710e-20) tensor(1.9406e-26)\n",
      "tensor(-1.4426e-19) tensor(1.2937e-26)\n",
      "tensor(-1.7799e-19) tensor(2.5875e-26)\n",
      "tensor(-3.8368e-19) tensor(0.)\n",
      "tensor(-3.3370e-19) tensor(2.5875e-26)\n",
      "tensor(2.5857e-20) tensor(0.)\n",
      "tensor(-8.9823e-22) tensor(3.0322e-28)\n",
      "tensor(-1.5282e-21) tensor(2.0215e-28)\n",
      "tensor(2.0202e-22) tensor(5.0536e-29)\n",
      "tensor(2.0503e-22) tensor(7.5805e-29)\n",
      "tensor(2.2060e-22) tensor(7.5805e-29)\n",
      "tensor(4.5813e-23) tensor(3.1585e-30)\n",
      "tensor(-1.5705e-24) tensor(0.)\n",
      "tensor(-6.3653e-25) tensor(4.9352e-32)\n",
      "tensor(-2.6397e-25) tensor(7.4028e-32)\n",
      "tensor(-7.5151e-26) tensor(6.1690e-33)\n",
      "tensor(3.1880e-26) tensor(3.0845e-33)\n",
      "tensor(9.8496e-27) tensor(2.3134e-33)\n",
      "tensor(-1.6129e-26) tensor(3.0845e-33)\n",
      "tensor(5.1326e-27) tensor(3.8556e-34)\n",
      "tensor(-2.6636e-27) tensor(3.8556e-34)\n",
      "tensor(4.3111e-27) tensor(3.8556e-34)\n",
      "tensor(7.2972e-28) tensor(1.9278e-34)\n",
      "tensor(4.3062e-28) tensor(4.8195e-35)\n",
      "tensor(-2.7062e-28) tensor(0.)\n",
      "tensor(-2.4578e-28) tensor(7.2293e-35)\n",
      "tensor(-1.4391e-28) tensor(1.2049e-35)\n",
      "tensor(1.2260e-29) tensor(4.5183e-36)\n",
      "tensor(-2.0590e-30) tensor(5.6479e-37)\n",
      "tensor(2.0499e-30) tensor(5.6479e-37)\n",
      "tensor(-2.8073e-31) tensor(7.0599e-38)\n",
      "tensor(-3.0802e-31) tensor(2.3533e-38)\n",
      "tensor(-7.1996e-32) tensor(5.8832e-39)\n",
      "tensor(-5.5211e-32) tensor(0.)\n",
      "tensor(-8.0401e-32) tensor(5.8832e-39)\n",
      "tensor(6.6884e-32) tensor(5.8832e-39)\n",
      "tensor(-8.4053e-32) tensor(2.3533e-38)\n",
      "tensor(1.8439e-32) tensor(1.4708e-39)\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(512,512)  # input image\n",
    "\n",
    "for i in range(100): \n",
    "    # init params for every layer\n",
    "    w = torch.randn(512) / math.sqrt(512)  # xavier init\n",
    "    b = torch.zeros(512)\n",
    "\n",
    "    a = lin(a, w, b)\n",
    "    print(a.mean(), a.std())\n",
    "    if torch.isinf(a.std()) or torch.isnan(a.std()):\n",
    "        print(f\"Numerical instability at layer {i}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ac5c6e",
   "metadata": {},
   "source": [
    "Let's do an ablation study and try Xavier init without using the bias term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f658a7c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0595) tensor(1.0453)\n",
      "tensor(-0.3266) tensor(nan)\n",
      "Numerical instability at layer 1\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(512,512)  # input image\n",
    "\n",
    "for i in range(100): \n",
    "    w = torch.randn(512) / math.sqrt(512)  # xavier init\n",
    "\n",
    "    a = lin(a, w)\n",
    "    print(a.mean(), a.std())\n",
    "    if torch.isinf(a.std()) or torch.isnan(a.std()):\n",
    "        print(f\"Numerical instability at layer {i}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29fa9ab",
   "metadata": {},
   "source": [
    "Removing the bias term shows that just a good init is not enough. The purpose of the bias term is to improve numerical stability in the forward pass. Without a bias term, it is harder to train deep architectures."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
